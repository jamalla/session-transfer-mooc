{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c73d08b",
   "metadata": {},
   "source": [
    "### 05 — Sessionization & Prefix→Target Generation\n",
    "\n",
    "**Goal:**  \n",
    "- For **Amazon Books 2023**: build synthetic sessions using **sliding windows** (Option A) to convert sparse user timelines into many sequence training examples.\n",
    "- For **MARS**: sessionize by **1 hour gap** (as decided in Step 04).\n",
    "- For **YOOCHOOSE**: use existing session IDs (already processed).\n",
    "- Generate `prefix -> target` pairs for training (next-item prediction).\n",
    "- Save outputs and report diagnostics.\n",
    "\n",
    "Outputs saved to `data/processed/`:\n",
    "- `amazon_windows_sessions.parquet` (or chunked files)\n",
    "- `amazon_prefix_target.parquet` (or chunked)\n",
    "- `mars_sessions.parquet`\n",
    "- `mars_prefix_target.parquet`\n",
    "- summary CSVs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fed9ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: imports & settings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "OUT_DIR = DATA_DIR\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parameters (tune as needed)\n",
    "WINDOW_SIZE = 20    # number of items in a sliding window\n",
    "STRIDE = 10         # step between windows\n",
    "MIN_WINDOW_ITEMS = 2  # min items to keep a window (>=2 gives at least one pair)\n",
    "MAX_PREFIX_LEN = 50  # cap prefix length when generating prefix-target\n",
    "MIN_SESSION_LEN = 2\n",
    "CHUNK_WRITE = True  # if True, write parquet in chunk files to avoid excessive RAM use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27816fd6",
   "metadata": {},
   "source": [
    "#### A — Helper functions\n",
    "- `build_sliding_windows()` : builds sliding-window sessions for Amazon (memory-efficient).\n",
    "- `sessionize_by_gap()` : sessionize a dataset by time-gap (used for MARS).\n",
    "- `generate_prefix_target()` : generate prefix→target pairs from a sessions DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb3f893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: helper function definitions\n",
    "def build_sliding_windows(df, user_col='user_id', item_col='item_id',\n",
    "                          time_col='timestamp', window_size=WINDOW_SIZE, stride=STRIDE,\n",
    "                          out_session_col='session_id_real'):\n",
    "    \"\"\"\n",
    "    Build sliding-window synthetic sessions from a user timeline DataFrame.\n",
    "    Returns a DataFrame with columns: dataset, user_id, session_id_real, item_id, timestamp\n",
    "    This version streams per-user and yields rows to reduce peak memory usage.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    # Ensure sorted\n",
    "    df = df.sort_values([user_col, time_col])\n",
    "    users = df[user_col].unique()\n",
    "    total_users = len(users)\n",
    "    print(f\"Users to process: {total_users:,}\")\n",
    "    \n",
    "    # iterate per user\n",
    "    for user in tqdm(users, desc=\"Building windows per user\"):\n",
    "        user_slice = df[df[user_col] == user]\n",
    "        items = user_slice[item_col].astype(str).tolist()\n",
    "        times = pd.to_datetime(user_slice[time_col]).tolist()\n",
    "        n = len(items)\n",
    "        if n < MIN_WINDOW_ITEMS:\n",
    "            continue\n",
    "        start = 0\n",
    "        win_idx = 0\n",
    "        while start < n:\n",
    "            end = min(start + window_size, n)\n",
    "            window_items = items[start:end]\n",
    "            window_times = times[start:end]\n",
    "            if len(window_items) >= MIN_WINDOW_ITEMS:\n",
    "                sess_id = f\"{user}__w{win_idx}_{start}\"\n",
    "                for it, ts in zip(window_items, window_times):\n",
    "                    rows.append({\n",
    "                        \"dataset\": \"amazon_books_2023\",\n",
    "                        \"user_id\": str(user),\n",
    "                        out_session_col: sess_id,\n",
    "                        \"item_id\": str(it),\n",
    "                        \"timestamp\": pd.to_datetime(ts)\n",
    "                    })\n",
    "                win_idx += 1\n",
    "            start += stride\n",
    "            # if rows accumulate too large, yield in batches (handled by caller)\n",
    "            if len(rows) >= 500_000:\n",
    "                yield pd.DataFrame(rows)\n",
    "                rows = []\n",
    "    # final flush\n",
    "    if rows:\n",
    "        yield pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def sessionize_by_gap(df, gap_seconds=3600, user_col='user_id', time_col='timestamp',\n",
    "                      out_session_col='session_id_real'):\n",
    "    \"\"\"\n",
    "    Sessionize by gap_seconds per user. Returns sessionized df and session summary.\n",
    "    \"\"\"\n",
    "    df = df.sort_values([user_col, time_col]).copy()\n",
    "    df[time_col] = pd.to_datetime(df[time_col])\n",
    "    df['prev_ts'] = df.groupby(user_col)[time_col].shift(1)\n",
    "    df['gap_s'] = (df[time_col] - df['prev_ts']).dt.total_seconds()\n",
    "    df['new_session'] = (df['gap_s'].isna()) | (df['gap_s'] > gap_seconds)\n",
    "    df['sess_idx'] = df.groupby(user_col)['new_session'].cumsum().astype(int)\n",
    "    df[out_session_col] = df[user_col].astype(str) + \"__s\" + df['sess_idx'].astype(str)\n",
    "    # summary\n",
    "    session_summary = df.groupby(out_session_col).agg(\n",
    "        dataset=('dataset','first'),\n",
    "        user_id=(user_col,'first'),\n",
    "        start_time=(time_col,'min'),\n",
    "        end_time=(time_col,'max'),\n",
    "        session_length=('item_id','size')\n",
    "    ).reset_index()\n",
    "    # filter short and very long sessions\n",
    "    valid_sessions = session_summary[\n",
    "        (session_summary['session_length'] >= MIN_SESSION_LEN)\n",
    "    ][out_session_col].tolist()\n",
    "    df = df[df[out_session_col].isin(valid_sessions)].copy()\n",
    "    df = df.drop(columns=['prev_ts','gap_s','new_session','sess_idx'], errors='ignore')\n",
    "    return df, session_summary\n",
    "\n",
    "def generate_prefix_target(df, session_col='session_id_real', item_col='item_id', max_prefix_len=MAX_PREFIX_LEN):\n",
    "    \"\"\"\n",
    "    From a sessionized df ordered by timestamp, generate prefix->target pairs.\n",
    "    Returns DataFrame with columns: dataset, user_id, session_id_real, prefix_len, prefix (space-separated), target\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    df = df.sort_values([session_col, 'timestamp'])\n",
    "    grouped = df.groupby(session_col)\n",
    "    for session_id, g in tqdm(grouped, desc=\"Generating prefix-target\"):\n",
    "        items = g[item_col].astype(str).tolist()\n",
    "        if len(items) < 2: continue\n",
    "        # optionally truncate to last (max_prefix_len + 1) items to limit explosion\n",
    "        if len(items) > max_prefix_len + 1:\n",
    "            items = items[-(max_prefix_len + 1):]\n",
    "        for t in range(1, len(items)):\n",
    "            prefix = items[:t]\n",
    "            target = items[t]\n",
    "            rows.append({\n",
    "                'dataset': g['dataset'].iloc[0],\n",
    "                'user_id': g['user_id'].iloc[0],\n",
    "                session_col: session_id,\n",
    "                'prefix_len': len(prefix),\n",
    "                'prefix': \" \".join(prefix),\n",
    "                'target': str(target)\n",
    "            })\n",
    "        # flush periodically if very large\n",
    "        if len(rows) >= 500_000:\n",
    "            yield pd.DataFrame(rows)\n",
    "            rows = []\n",
    "    if rows:\n",
    "        yield pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "616ab7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction users with count==1: 0.5772661819019989\n"
     ]
    }
   ],
   "source": [
    "# quick count per user (single-pass). If parquet fits in RAM you can do it with pandas.\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "p = Path(\"../data/processed/amazon_books_2023_interactions.parquet\")\n",
    "df = pd.read_parquet(p, columns=[\"user_id\"])   # only this col -> lower memory\n",
    "vc = df[\"user_id\"].value_counts()\n",
    "vc.describe(percentiles=[0.5,0.75,0.9,0.99])\n",
    "print(\"fraction users with count==1:\", (vc==1).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa95cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users with count >= 1: 9,614,012  (fraction=1.0000)\n",
      "users with count >= 2: 4,064,168  (fraction=0.4227)\n",
      "users with count >= 3: 2,315,212  (fraction=0.2408)\n",
      "users with count >= 5: 1,102,772  (fraction=0.1147)\n",
      "users with count >= 10: 380,903  (fraction=0.0396)\n",
      "top 100000 users: 100000\n",
      "top 500000 users: 500000\n",
      "top 1000000 users: 1000000\n"
     ]
    }
   ],
   "source": [
    "p = Path(\"../data/processed/amazon_books_2023_interactions.parquet\")\n",
    "# load only user_id column (fast)\n",
    "df_u = pd.read_parquet(p, columns=[\"user_id\"])\n",
    "vc = df_u[\"user_id\"].value_counts()\n",
    "for cut in [1,2,3,5,10]:\n",
    "    kept = (vc >= cut).sum()\n",
    "    print(f\"users with count >= {cut}: {kept:,}  (fraction={kept/len(vc):.4f})\")\n",
    "# top-K example\n",
    "for k in [100_000, 500_000, 1_000_000]:\n",
    "    topk = vc.nlargest(k).index.size\n",
    "    print(f\"top {k} users: {topk}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4991246e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba5234938cd49fd8a64b9abd3bb998e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created amazon_active_count_ge2.parquet\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "duckdb.sql(\"\"\"\n",
    "COPY (\n",
    "  SELECT *\n",
    "  FROM read_parquet('../data/processed/amazon_books_2023_interactions.parquet')\n",
    "  WHERE user_id IN (\n",
    "    SELECT user_id FROM read_parquet('../data/processed/amazon_books_2023_interactions.parquet')\n",
    "    GROUP BY user_id HAVING COUNT(*) >= 2\n",
    "  )\n",
    ") TO '../data/processed/amazon_active_count_ge2.parquet' (FORMAT PARQUET);\n",
    "\"\"\")\n",
    "print(\"Created amazon_active_count_ge2.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f4f5f3",
   "metadata": {},
   "source": [
    "Step C — Build sliding windows from filtered file\n",
    "Option C.1 — Single-process (simple, uses groupby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7119250e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4064168/4064168 [12:55<00:00, 5242.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 55 parts; total rows: 27036156\n"
     ]
    }
   ],
   "source": [
    "WINDOW_SIZE = 20\n",
    "STRIDE = 10\n",
    "MIN_WINDOW_ITEMS = 2\n",
    "OUT_DIR = Path(\"../data/processed\")\n",
    "in_path = OUT_DIR / \"amazon_active_count_ge2.parquet\"  # or amazon_top1M.parquet\n",
    "\n",
    "df = pd.read_parquet(in_path)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df.sort_values(['user_id','timestamp'])\n",
    "\n",
    "out_rows = []\n",
    "out_parts = []\n",
    "flush_every = 500000  # rows per part\n",
    "part_idx = 0\n",
    "count_rows = 0\n",
    "\n",
    "for user, g in tqdm(df.groupby('user_id'), total=df['user_id'].nunique()):\n",
    "    items = g['item_id'].astype(str).tolist()\n",
    "    times = g['timestamp'].tolist()\n",
    "    n = len(items)\n",
    "    if n < MIN_WINDOW_ITEMS:\n",
    "        continue\n",
    "    start = 0\n",
    "    win_idx = 0\n",
    "    while start < n:\n",
    "        end = min(start + WINDOW_SIZE, n)\n",
    "        window_items = items[start:end]\n",
    "        window_times = times[start:end]\n",
    "        if len(window_items) >= MIN_WINDOW_ITEMS:\n",
    "            sess_id = f\"{user}__w{win_idx}_{start}\"\n",
    "            for it, ts in zip(window_items, window_times):\n",
    "                out_rows.append({\n",
    "                    \"dataset\": \"amazon_books_2023\",\n",
    "                    \"user_id\": str(user),\n",
    "                    \"session_id_real\": sess_id,\n",
    "                    \"item_id\": str(it),\n",
    "                    \"timestamp\": pd.to_datetime(ts)\n",
    "                })\n",
    "            win_idx += 1\n",
    "        start += STRIDE\n",
    "        if len(out_rows) >= flush_every:\n",
    "            part = pd.DataFrame(out_rows)\n",
    "            part_path = OUT_DIR / f\"amazon_windows_sessions_part{part_idx:03d}.parquet\"\n",
    "            part.to_parquet(part_path, index=False)\n",
    "            out_parts.append(part_path)\n",
    "            count_rows += len(part)\n",
    "            out_rows = []\n",
    "            part_idx += 1\n",
    "\n",
    "# final flush\n",
    "if out_rows:\n",
    "    part = pd.DataFrame(out_rows)\n",
    "    part_path = OUT_DIR / f\"amazon_windows_sessions_part{part_idx:03d}.parquet\"\n",
    "    part.to_parquet(part_path, index=False)\n",
    "    out_parts.append(part_path)\n",
    "    count_rows += len(part)\n",
    "\n",
    "print(\"Wrote\", len(out_parts), \"parts; total rows:\", count_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e08e331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 parts\n",
      "Total events across parts: 27036156\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "parts = sorted(DATA_DIR.glob(\"amazon_windows_sessions_part*.parquet\"))\n",
    "print(\"Found\", len(parts), \"parts\")\n",
    "\n",
    "# quick totals\n",
    "total_events = 0\n",
    "for p in parts:\n",
    "    # read only number of rows — with pandas you get memory for that part only\n",
    "    dfp = pd.read_parquet(p, columns=[\"session_id_real\"])\n",
    "    total_events += len(dfp)\n",
    "print(\"Total events across parts:\", total_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad4d743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 55 parts to ..\\data\\processed\\amazon_windows_parts\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "parts = sorted(DATA_DIR.glob(\"amazon_windows_sessions_part*.parquet\"))\n",
    "len(parts)\n",
    "# create target folder\n",
    "parts_dir = DATA_DIR / \"amazon_windows_parts\"\n",
    "parts_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for p in parts:\n",
    "    dest = parts_dir / p.name\n",
    "    shutil.move(str(p), str(dest))\n",
    "\n",
    "print(\"Moved\", len(list(parts_dir.glob(\"amazon_windows_sessions_part*.parquet\"))), \"parts to\", parts_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ffe9762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 parts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting per-session lengths: 100%|██████████| 55/55 [00:11<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events counted across parts: 27036156\n",
      "Total sessions: 4745988\n",
      "count    4.745988e+06\n",
      "mean     5.696634e+00\n",
      "std      5.563629e+00\n",
      "min      2.000000e+00\n",
      "25%      2.000000e+00\n",
      "50%      3.000000e+00\n",
      "75%      6.000000e+00\n",
      "90%      1.700000e+01\n",
      "95%      2.000000e+01\n",
      "99%      2.000000e+01\n",
      "max      2.000000e+01\n",
      "Name: length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "\n",
    "parts_dir = Path(\"../data/processed/amazon_windows_parts\")\n",
    "parts = sorted(parts_dir.glob(\"amazon_windows_sessions_part*.parquet\"))\n",
    "print(\"Found\", len(parts), \"parts\")\n",
    "\n",
    "sess_counter = Counter()\n",
    "total_events = 0\n",
    "\n",
    "for p in tqdm.tqdm(parts, desc=\"Counting per-session lengths\"):\n",
    "    dfp = pd.read_parquet(p, columns=[\"session_id_real\"])\n",
    "    vc = dfp[\"session_id_real\"].value_counts()\n",
    "    total_events += len(dfp)\n",
    "    # vc is a Series: index=session_id_real, value=count\n",
    "    for sid, cnt in vc.items():\n",
    "        sess_counter[sid] += int(cnt)\n",
    "\n",
    "print(\"Total events counted across parts:\", total_events)\n",
    "\n",
    "# build DataFrame from Counter safely\n",
    "sess_items = list(sess_counter.items())  # list of (session_id, length)\n",
    "sess_df = pd.DataFrame(sess_items, columns=[\"session_id_real\", \"length\"])\n",
    "sess_df['length'] = sess_df['length'].astype(int)\n",
    "\n",
    "print(\"Total sessions:\", len(sess_df))\n",
    "print(sess_df['length'].describe(percentiles=[.25,.5,.75,.9,.95,.99]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a98feafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved session summary to ..\\data\\processed\\amazon_windows_session_summary.csv\n"
     ]
    }
   ],
   "source": [
    "sess_df.to_csv(DATA_DIR / \"amazon_windows_session_summary.csv\", index=False)\n",
    "print(\"Saved session summary to\", DATA_DIR / \"amazon_windows_session_summary.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b74b220",
   "metadata": {},
   "source": [
    "#### D — Generate prefix→target pairs for Amazon (stream chunked parts)\n",
    "Read each window-session chunk and generate prefix-target pairs streaming to chunked parquet files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b046f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:   0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0000.parquet (#pairs=200,000); total_pairs=200,000\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0001.parquet (#pairs=200,000); total_pairs=400,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:   2%|▏         | 1/55 [00:20<18:06, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0002.parquet (#pairs=12,544); total_pairs=412,544\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0003.parquet (#pairs=200,000); total_pairs=612,544\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0004.parquet (#pairs=200,000); total_pairs=812,544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:   4%|▎         | 2/55 [00:40<17:42, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0005.parquet (#pairs=10,989); total_pairs=823,533\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0006.parquet (#pairs=200,000); total_pairs=1,023,533\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0007.parquet (#pairs=200,000); total_pairs=1,223,533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:   5%|▌         | 3/55 [00:59<17:17, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0008.parquet (#pairs=12,115); total_pairs=1,235,648\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0009.parquet (#pairs=200,000); total_pairs=1,435,648\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0010.parquet (#pairs=200,000); total_pairs=1,635,648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:   7%|▋         | 4/55 [01:19<16:56, 19.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0011.parquet (#pairs=12,875); total_pairs=1,648,523\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0012.parquet (#pairs=200,000); total_pairs=1,848,523\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0013.parquet (#pairs=200,000); total_pairs=2,048,523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:   9%|▉         | 5/55 [01:40<16:43, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0014.parquet (#pairs=10,463); total_pairs=2,058,986\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0015.parquet (#pairs=200,000); total_pairs=2,258,986\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0016.parquet (#pairs=200,000); total_pairs=2,458,986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  11%|█         | 6/55 [02:00<16:35, 20.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0017.parquet (#pairs=10,699); total_pairs=2,469,685\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0018.parquet (#pairs=200,000); total_pairs=2,669,685\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0019.parquet (#pairs=200,000); total_pairs=2,869,685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  13%|█▎        | 7/55 [02:21<16:14, 20.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0020.parquet (#pairs=12,183); total_pairs=2,881,868\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0021.parquet (#pairs=200,000); total_pairs=3,081,868\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0022.parquet (#pairs=200,000); total_pairs=3,281,868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  15%|█▍        | 8/55 [02:41<15:55, 20.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0023.parquet (#pairs=11,524); total_pairs=3,293,392\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0024.parquet (#pairs=200,000); total_pairs=3,493,392\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0025.parquet (#pairs=200,000); total_pairs=3,693,392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  16%|█▋        | 9/55 [03:01<15:33, 20.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0026.parquet (#pairs=12,619); total_pairs=3,706,011\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0027.parquet (#pairs=200,000); total_pairs=3,906,011\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0028.parquet (#pairs=200,000); total_pairs=4,106,011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  18%|█▊        | 10/55 [03:21<15:10, 20.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0029.parquet (#pairs=10,746); total_pairs=4,116,757\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0030.parquet (#pairs=200,000); total_pairs=4,316,757\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0031.parquet (#pairs=200,000); total_pairs=4,516,757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  20%|██        | 11/55 [03:41<14:43, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0032.parquet (#pairs=13,252); total_pairs=4,530,009\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0033.parquet (#pairs=200,000); total_pairs=4,730,009\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0034.parquet (#pairs=200,000); total_pairs=4,930,009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  22%|██▏       | 12/55 [04:02<14:31, 20.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0035.parquet (#pairs=11,433); total_pairs=4,941,442\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0036.parquet (#pairs=200,000); total_pairs=5,141,442\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0037.parquet (#pairs=200,000); total_pairs=5,341,442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  24%|██▎       | 13/55 [04:23<14:19, 20.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0038.parquet (#pairs=10,992); total_pairs=5,352,434\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0039.parquet (#pairs=200,000); total_pairs=5,552,434\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0040.parquet (#pairs=200,000); total_pairs=5,752,434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  25%|██▌       | 14/55 [04:43<13:57, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0041.parquet (#pairs=11,429); total_pairs=5,763,863\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0042.parquet (#pairs=200,000); total_pairs=5,963,863\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0043.parquet (#pairs=200,000); total_pairs=6,163,863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  27%|██▋       | 15/55 [05:06<14:08, 21.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0044.parquet (#pairs=12,463); total_pairs=6,176,326\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0045.parquet (#pairs=200,000); total_pairs=6,376,326\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0046.parquet (#pairs=200,000); total_pairs=6,576,326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  29%|██▉       | 16/55 [05:26<13:36, 20.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0047.parquet (#pairs=12,935); total_pairs=6,589,261\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0048.parquet (#pairs=200,000); total_pairs=6,789,261\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0049.parquet (#pairs=200,000); total_pairs=6,989,261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  31%|███       | 17/55 [05:47<13:15, 20.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0050.parquet (#pairs=11,643); total_pairs=7,000,904\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0051.parquet (#pairs=200,000); total_pairs=7,200,904\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0052.parquet (#pairs=200,000); total_pairs=7,400,904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  33%|███▎      | 18/55 [06:10<13:07, 21.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0053.parquet (#pairs=12,216); total_pairs=7,413,120\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0054.parquet (#pairs=200,000); total_pairs=7,613,120\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0055.parquet (#pairs=200,000); total_pairs=7,813,120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  35%|███▍      | 19/55 [06:30<12:34, 20.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0056.parquet (#pairs=12,782); total_pairs=7,825,902\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0057.parquet (#pairs=200,000); total_pairs=8,025,902\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0058.parquet (#pairs=200,000); total_pairs=8,225,902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  36%|███▋      | 20/55 [06:49<11:59, 20.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0059.parquet (#pairs=12,893); total_pairs=8,238,795\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0060.parquet (#pairs=200,000); total_pairs=8,438,795\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0061.parquet (#pairs=200,000); total_pairs=8,638,795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  38%|███▊      | 21/55 [07:09<11:32, 20.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0062.parquet (#pairs=13,678); total_pairs=8,652,473\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0063.parquet (#pairs=200,000); total_pairs=8,852,473\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0064.parquet (#pairs=200,000); total_pairs=9,052,473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  40%|████      | 22/55 [07:30<11:14, 20.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0065.parquet (#pairs=12,465); total_pairs=9,064,938\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0066.parquet (#pairs=200,000); total_pairs=9,264,938\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0067.parquet (#pairs=200,000); total_pairs=9,464,938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  42%|████▏     | 23/55 [07:50<10:49, 20.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0068.parquet (#pairs=12,540); total_pairs=9,477,478\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0069.parquet (#pairs=200,000); total_pairs=9,677,478\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0070.parquet (#pairs=200,000); total_pairs=9,877,478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  44%|████▎     | 24/55 [08:11<10:34, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0071.parquet (#pairs=10,936); total_pairs=9,888,414\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0072.parquet (#pairs=200,000); total_pairs=10,088,414\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0073.parquet (#pairs=200,000); total_pairs=10,288,414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  45%|████▌     | 25/55 [08:31<10:10, 20.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0074.parquet (#pairs=12,298); total_pairs=10,300,712\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0075.parquet (#pairs=200,000); total_pairs=10,500,712\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0076.parquet (#pairs=200,000); total_pairs=10,700,712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  47%|████▋     | 26/55 [08:50<09:44, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0077.parquet (#pairs=12,458); total_pairs=10,713,170\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0078.parquet (#pairs=200,000); total_pairs=10,913,170\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0079.parquet (#pairs=200,000); total_pairs=11,113,170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  49%|████▉     | 27/55 [09:10<09:20, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0080.parquet (#pairs=10,526); total_pairs=11,123,696\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0081.parquet (#pairs=200,000); total_pairs=11,323,696\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0082.parquet (#pairs=200,000); total_pairs=11,523,696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  51%|█████     | 28/55 [09:30<08:57, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0083.parquet (#pairs=13,445); total_pairs=11,537,141\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0084.parquet (#pairs=200,000); total_pairs=11,737,141\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0085.parquet (#pairs=200,000); total_pairs=11,937,141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  53%|█████▎    | 29/55 [09:52<08:52, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0086.parquet (#pairs=11,204); total_pairs=11,948,345\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0087.parquet (#pairs=200,000); total_pairs=12,148,345\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0088.parquet (#pairs=200,000); total_pairs=12,348,345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  55%|█████▍    | 30/55 [10:12<08:29, 20.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0089.parquet (#pairs=12,325); total_pairs=12,360,670\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0090.parquet (#pairs=200,000); total_pairs=12,560,670\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0091.parquet (#pairs=200,000); total_pairs=12,760,670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  56%|█████▋    | 31/55 [10:32<08:06, 20.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0092.parquet (#pairs=10,191); total_pairs=12,770,861\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0093.parquet (#pairs=200,000); total_pairs=12,970,861\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0094.parquet (#pairs=200,000); total_pairs=13,170,861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  58%|█████▊    | 32/55 [10:53<07:51, 20.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0095.parquet (#pairs=11,914); total_pairs=13,182,775\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0096.parquet (#pairs=200,000); total_pairs=13,382,775\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0097.parquet (#pairs=200,000); total_pairs=13,582,775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  60%|██████    | 33/55 [11:14<07:33, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0098.parquet (#pairs=12,187); total_pairs=13,594,962\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0099.parquet (#pairs=200,000); total_pairs=13,794,962\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0100.parquet (#pairs=200,000); total_pairs=13,994,962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  62%|██████▏   | 34/55 [11:34<07:09, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0101.parquet (#pairs=10,705); total_pairs=14,005,667\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0102.parquet (#pairs=200,000); total_pairs=14,205,667\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0103.parquet (#pairs=200,000); total_pairs=14,405,667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  64%|██████▎   | 35/55 [11:55<06:51, 20.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0104.parquet (#pairs=11,652); total_pairs=14,417,319\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0105.parquet (#pairs=200,000); total_pairs=14,617,319\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0106.parquet (#pairs=200,000); total_pairs=14,817,319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  65%|██████▌   | 36/55 [12:16<06:37, 20.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0107.parquet (#pairs=12,190); total_pairs=14,829,509\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0108.parquet (#pairs=200,000); total_pairs=15,029,509\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0109.parquet (#pairs=200,000); total_pairs=15,229,509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  67%|██████▋   | 37/55 [12:39<06:24, 21.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0110.parquet (#pairs=12,720); total_pairs=15,242,229\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0111.parquet (#pairs=200,000); total_pairs=15,442,229\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0112.parquet (#pairs=200,000); total_pairs=15,642,229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  69%|██████▉   | 38/55 [13:03<06:16, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0113.parquet (#pairs=12,806); total_pairs=15,655,035\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0114.parquet (#pairs=200,000); total_pairs=15,855,035\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0115.parquet (#pairs=200,000); total_pairs=16,055,035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  71%|███████   | 39/55 [13:26<05:57, 22.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0116.parquet (#pairs=13,661); total_pairs=16,068,696\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0117.parquet (#pairs=200,000); total_pairs=16,268,696\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0118.parquet (#pairs=200,000); total_pairs=16,468,696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  73%|███████▎  | 40/55 [13:49<05:40, 22.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0119.parquet (#pairs=12,032); total_pairs=16,480,728\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0120.parquet (#pairs=200,000); total_pairs=16,680,728\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0121.parquet (#pairs=200,000); total_pairs=16,880,728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  75%|███████▍  | 41/55 [14:13<05:23, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0122.parquet (#pairs=14,613); total_pairs=16,895,341\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0123.parquet (#pairs=200,000); total_pairs=17,095,341\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0124.parquet (#pairs=200,000); total_pairs=17,295,341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  76%|███████▋  | 42/55 [14:36<05:00, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0125.parquet (#pairs=11,968); total_pairs=17,307,309\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0126.parquet (#pairs=200,000); total_pairs=17,507,309\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0127.parquet (#pairs=200,000); total_pairs=17,707,309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  78%|███████▊  | 43/55 [15:01<04:43, 23.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0128.parquet (#pairs=14,245); total_pairs=17,721,554\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0129.parquet (#pairs=200,000); total_pairs=17,921,554\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0130.parquet (#pairs=200,000); total_pairs=18,121,554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  80%|████████  | 44/55 [15:23<04:14, 23.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0131.parquet (#pairs=14,598); total_pairs=18,136,152\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0132.parquet (#pairs=200,000); total_pairs=18,336,152\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0133.parquet (#pairs=200,000); total_pairs=18,536,152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  82%|████████▏ | 45/55 [15:44<03:44, 22.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0134.parquet (#pairs=11,179); total_pairs=18,547,331\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0135.parquet (#pairs=200,000); total_pairs=18,747,331\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0136.parquet (#pairs=200,000); total_pairs=18,947,331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  84%|████████▎ | 46/55 [16:06<03:21, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0137.parquet (#pairs=11,880); total_pairs=18,959,211\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0138.parquet (#pairs=200,000); total_pairs=19,159,211\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0139.parquet (#pairs=200,000); total_pairs=19,359,211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  85%|████████▌ | 47/55 [16:27<02:55, 21.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0140.parquet (#pairs=11,501); total_pairs=19,370,712\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0141.parquet (#pairs=200,000); total_pairs=19,570,712\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0142.parquet (#pairs=200,000); total_pairs=19,770,712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  87%|████████▋ | 48/55 [16:46<02:28, 21.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0143.parquet (#pairs=16,700); total_pairs=19,787,412\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0144.parquet (#pairs=200,000); total_pairs=19,987,412\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0145.parquet (#pairs=200,000); total_pairs=20,187,412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  89%|████████▉ | 49/55 [17:06<02:05, 20.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0146.parquet (#pairs=12,848); total_pairs=20,200,260\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0147.parquet (#pairs=200,000); total_pairs=20,400,260\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0148.parquet (#pairs=200,000); total_pairs=20,600,260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  91%|█████████ | 50/55 [17:28<01:45, 21.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0149.parquet (#pairs=12,466); total_pairs=20,612,726\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0150.parquet (#pairs=200,000); total_pairs=20,812,726\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0151.parquet (#pairs=200,000); total_pairs=21,012,726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  93%|█████████▎| 51/55 [17:50<01:25, 21.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0152.parquet (#pairs=10,903); total_pairs=21,023,629\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0153.parquet (#pairs=200,000); total_pairs=21,223,629\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0154.parquet (#pairs=200,000); total_pairs=21,423,629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  95%|█████████▍| 52/55 [18:14<01:05, 21.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0155.parquet (#pairs=11,802); total_pairs=21,435,431\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0156.parquet (#pairs=200,000); total_pairs=21,635,431\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0157.parquet (#pairs=200,000); total_pairs=21,835,431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  96%|█████████▋| 53/55 [18:35<00:43, 21.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0158.parquet (#pairs=13,541); total_pairs=21,848,972\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0159.parquet (#pairs=200,000); total_pairs=22,048,972\n",
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0160.parquet (#pairs=200,000); total_pairs=22,248,972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts:  98%|█████████▊| 54/55 [18:55<00:21, 21.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0161.parquet (#pairs=11,143); total_pairs=22,260,115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prefix-target parts: 100%|██████████| 55/55 [18:57<00:00, 20.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ..\\data\\processed\\amazon_prefix_parts\\amazon_prefix_target_part0162.parquet (#pairs=30,053); total_pairs=22,290,168\n",
      "Done. Total prefix-target pairs: 22290168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "parts_dir = Path(\"../data/processed/amazon_windows_parts\")\n",
    "pair_out_dir = Path(\"../data/processed/amazon_prefix_parts\")\n",
    "pair_out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "FLUSH = 200_000\n",
    "pair_idx = 0\n",
    "total_pairs = 0\n",
    "\n",
    "def gen_pairs_from_df(df_part, session_col='session_id_real', item_col='item_id', max_prefix_len=50):\n",
    "    df_part = df_part.sort_values([session_col, 'timestamp'])\n",
    "    rows = []\n",
    "    for session_id, g in df_part.groupby(session_col):\n",
    "        items = g[item_col].astype(str).tolist()\n",
    "        if len(items) < 2:\n",
    "            continue\n",
    "        if len(items) > max_prefix_len + 1:\n",
    "            items = items[-(max_prefix_len + 1):]\n",
    "        for t in range(1, len(items)):\n",
    "            rows.append({\n",
    "                'dataset': g['dataset'].iloc[0],\n",
    "                'user_id': g['user_id'].iloc[0],\n",
    "                session_col: session_id,\n",
    "                'prefix_len': t,\n",
    "                'prefix': \" \".join(items[:t]),\n",
    "                'target': str(items[t])\n",
    "            })\n",
    "            if len(rows) >= FLUSH:\n",
    "                yield pd.DataFrame(rows)\n",
    "                rows = []\n",
    "    if rows:\n",
    "        yield pd.DataFrame(rows)\n",
    "\n",
    "# process each part file and write pair-parquet parts\n",
    "for p in tqdm.tqdm(parts, desc=\"Generating prefix-target parts\"):\n",
    "    dfp = pd.read_parquet(p)\n",
    "    for df_pairs in gen_pairs_from_df(dfp, max_prefix_len=50):\n",
    "        outp = pair_out_dir / f\"amazon_prefix_target_part{pair_idx:04d}.parquet\"\n",
    "        df_pairs.to_parquet(outp, index=False)\n",
    "        total_pairs += len(df_pairs)\n",
    "        pair_idx += 1\n",
    "        print(f\"Wrote {outp} (#pairs={len(df_pairs):,}); total_pairs={total_pairs:,}\")\n",
    "\n",
    "print(\"Done. Total prefix-target pairs:\", total_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28a15d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found parts: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting per-session lengths: 100%|██████████| 55/55 [00:11<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total events counted across parts: 27036156\n",
      "Total sessions: 4745988\n",
      "count    4.745988e+06\n",
      "mean     5.696634e+00\n",
      "std      5.563629e+00\n",
      "min      2.000000e+00\n",
      "25%      2.000000e+00\n",
      "50%      3.000000e+00\n",
      "75%      6.000000e+00\n",
      "90%      1.700000e+01\n",
      "95%      2.000000e+01\n",
      "99%      2.000000e+01\n",
      "max      2.000000e+01\n",
      "Name: length, dtype: float64\n",
      "Saved session summary CSV to: ..\\data\\processed\\amazon_windows_session_summary_from_parts.csv\n",
      "\n",
      "Start generating prefix->target parts (this can take time)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:   0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0000.parquet  (#pairs=200,000)  total_pairs=200,000\n",
      "Wrote amazon_prefix_target_part0001.parquet  (#pairs=200,000)  total_pairs=400,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:   2%|▏         | 1/55 [00:20<18:16, 20.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0002.parquet  (#pairs=12,544)  total_pairs=412,544\n",
      "Wrote amazon_prefix_target_part0003.parquet  (#pairs=200,000)  total_pairs=612,544\n",
      "Wrote amazon_prefix_target_part0004.parquet  (#pairs=200,000)  total_pairs=812,544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:   4%|▎         | 2/55 [00:41<18:15, 20.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0005.parquet  (#pairs=10,989)  total_pairs=823,533\n",
      "Wrote amazon_prefix_target_part0006.parquet  (#pairs=200,000)  total_pairs=1,023,533\n",
      "Wrote amazon_prefix_target_part0007.parquet  (#pairs=200,000)  total_pairs=1,223,533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:   5%|▌         | 3/55 [01:02<18:01, 20.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0008.parquet  (#pairs=12,115)  total_pairs=1,235,648\n",
      "Wrote amazon_prefix_target_part0009.parquet  (#pairs=200,000)  total_pairs=1,435,648\n",
      "Wrote amazon_prefix_target_part0010.parquet  (#pairs=200,000)  total_pairs=1,635,648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:   7%|▋         | 4/55 [01:22<17:37, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0011.parquet  (#pairs=12,875)  total_pairs=1,648,523\n",
      "Wrote amazon_prefix_target_part0012.parquet  (#pairs=200,000)  total_pairs=1,848,523\n",
      "Wrote amazon_prefix_target_part0013.parquet  (#pairs=200,000)  total_pairs=2,048,523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:   9%|▉         | 5/55 [01:44<17:27, 20.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0014.parquet  (#pairs=10,463)  total_pairs=2,058,986\n",
      "Wrote amazon_prefix_target_part0015.parquet  (#pairs=200,000)  total_pairs=2,258,986\n",
      "Wrote amazon_prefix_target_part0016.parquet  (#pairs=200,000)  total_pairs=2,458,986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  11%|█         | 6/55 [02:06<17:36, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0017.parquet  (#pairs=10,699)  total_pairs=2,469,685\n",
      "Wrote amazon_prefix_target_part0018.parquet  (#pairs=200,000)  total_pairs=2,669,685\n",
      "Wrote amazon_prefix_target_part0019.parquet  (#pairs=200,000)  total_pairs=2,869,685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  13%|█▎        | 7/55 [02:27<17:05, 21.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0020.parquet  (#pairs=12,183)  total_pairs=2,881,868\n",
      "Wrote amazon_prefix_target_part0021.parquet  (#pairs=200,000)  total_pairs=3,081,868\n",
      "Wrote amazon_prefix_target_part0022.parquet  (#pairs=200,000)  total_pairs=3,281,868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  15%|█▍        | 8/55 [02:49<16:45, 21.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0023.parquet  (#pairs=11,524)  total_pairs=3,293,392\n",
      "Wrote amazon_prefix_target_part0024.parquet  (#pairs=200,000)  total_pairs=3,493,392\n",
      "Wrote amazon_prefix_target_part0025.parquet  (#pairs=200,000)  total_pairs=3,693,392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  16%|█▋        | 9/55 [03:09<16:03, 20.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0026.parquet  (#pairs=12,619)  total_pairs=3,706,011\n",
      "Wrote amazon_prefix_target_part0027.parquet  (#pairs=200,000)  total_pairs=3,906,011\n",
      "Wrote amazon_prefix_target_part0028.parquet  (#pairs=200,000)  total_pairs=4,106,011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  18%|█▊        | 10/55 [03:29<15:34, 20.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0029.parquet  (#pairs=10,746)  total_pairs=4,116,757\n",
      "Wrote amazon_prefix_target_part0030.parquet  (#pairs=200,000)  total_pairs=4,316,757\n",
      "Wrote amazon_prefix_target_part0031.parquet  (#pairs=200,000)  total_pairs=4,516,757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  20%|██        | 11/55 [03:49<14:59, 20.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0032.parquet  (#pairs=13,252)  total_pairs=4,530,009\n",
      "Wrote amazon_prefix_target_part0033.parquet  (#pairs=200,000)  total_pairs=4,730,009\n",
      "Wrote amazon_prefix_target_part0034.parquet  (#pairs=200,000)  total_pairs=4,930,009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  22%|██▏       | 12/55 [04:10<14:46, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0035.parquet  (#pairs=11,433)  total_pairs=4,941,442\n",
      "Wrote amazon_prefix_target_part0036.parquet  (#pairs=200,000)  total_pairs=5,141,442\n",
      "Wrote amazon_prefix_target_part0037.parquet  (#pairs=200,000)  total_pairs=5,341,442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  24%|██▎       | 13/55 [04:30<14:25, 20.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0038.parquet  (#pairs=10,992)  total_pairs=5,352,434\n",
      "Wrote amazon_prefix_target_part0039.parquet  (#pairs=200,000)  total_pairs=5,552,434\n",
      "Wrote amazon_prefix_target_part0040.parquet  (#pairs=200,000)  total_pairs=5,752,434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  25%|██▌       | 14/55 [04:51<14:09, 20.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0041.parquet  (#pairs=11,429)  total_pairs=5,763,863\n",
      "Wrote amazon_prefix_target_part0042.parquet  (#pairs=200,000)  total_pairs=5,963,863\n",
      "Wrote amazon_prefix_target_part0043.parquet  (#pairs=200,000)  total_pairs=6,163,863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  27%|██▋       | 15/55 [05:14<14:15, 21.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0044.parquet  (#pairs=12,463)  total_pairs=6,176,326\n",
      "Wrote amazon_prefix_target_part0045.parquet  (#pairs=200,000)  total_pairs=6,376,326\n",
      "Wrote amazon_prefix_target_part0046.parquet  (#pairs=200,000)  total_pairs=6,576,326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  29%|██▉       | 16/55 [05:34<13:35, 20.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0047.parquet  (#pairs=12,935)  total_pairs=6,589,261\n",
      "Wrote amazon_prefix_target_part0048.parquet  (#pairs=200,000)  total_pairs=6,789,261\n",
      "Wrote amazon_prefix_target_part0049.parquet  (#pairs=200,000)  total_pairs=6,989,261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  31%|███       | 17/55 [05:54<13:06, 20.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0050.parquet  (#pairs=11,643)  total_pairs=7,000,904\n",
      "Wrote amazon_prefix_target_part0051.parquet  (#pairs=200,000)  total_pairs=7,200,904\n",
      "Wrote amazon_prefix_target_part0052.parquet  (#pairs=200,000)  total_pairs=7,400,904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  33%|███▎      | 18/55 [06:15<12:48, 20.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0053.parquet  (#pairs=12,216)  total_pairs=7,413,120\n",
      "Wrote amazon_prefix_target_part0054.parquet  (#pairs=200,000)  total_pairs=7,613,120\n",
      "Wrote amazon_prefix_target_part0055.parquet  (#pairs=200,000)  total_pairs=7,813,120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  35%|███▍      | 19/55 [06:35<12:14, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0056.parquet  (#pairs=12,782)  total_pairs=7,825,902\n",
      "Wrote amazon_prefix_target_part0057.parquet  (#pairs=200,000)  total_pairs=8,025,902\n",
      "Wrote amazon_prefix_target_part0058.parquet  (#pairs=200,000)  total_pairs=8,225,902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  36%|███▋      | 20/55 [06:55<11:47, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0059.parquet  (#pairs=12,893)  total_pairs=8,238,795\n",
      "Wrote amazon_prefix_target_part0060.parquet  (#pairs=200,000)  total_pairs=8,438,795\n",
      "Wrote amazon_prefix_target_part0061.parquet  (#pairs=200,000)  total_pairs=8,638,795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  38%|███▊      | 21/55 [07:14<11:20, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0062.parquet  (#pairs=13,678)  total_pairs=8,652,473\n",
      "Wrote amazon_prefix_target_part0063.parquet  (#pairs=200,000)  total_pairs=8,852,473\n",
      "Wrote amazon_prefix_target_part0064.parquet  (#pairs=200,000)  total_pairs=9,052,473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  40%|████      | 22/55 [07:34<10:57, 19.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0065.parquet  (#pairs=12,465)  total_pairs=9,064,938\n",
      "Wrote amazon_prefix_target_part0066.parquet  (#pairs=200,000)  total_pairs=9,264,938\n",
      "Wrote amazon_prefix_target_part0067.parquet  (#pairs=200,000)  total_pairs=9,464,938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  42%|████▏     | 23/55 [07:54<10:41, 20.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0068.parquet  (#pairs=12,540)  total_pairs=9,477,478\n",
      "Wrote amazon_prefix_target_part0069.parquet  (#pairs=200,000)  total_pairs=9,677,478\n",
      "Wrote amazon_prefix_target_part0070.parquet  (#pairs=200,000)  total_pairs=9,877,478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  44%|████▎     | 24/55 [08:14<10:23, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0071.parquet  (#pairs=10,936)  total_pairs=9,888,414\n",
      "Wrote amazon_prefix_target_part0072.parquet  (#pairs=200,000)  total_pairs=10,088,414\n",
      "Wrote amazon_prefix_target_part0073.parquet  (#pairs=200,000)  total_pairs=10,288,414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  45%|████▌     | 25/55 [08:34<10:00, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0074.parquet  (#pairs=12,298)  total_pairs=10,300,712\n",
      "Wrote amazon_prefix_target_part0075.parquet  (#pairs=200,000)  total_pairs=10,500,712\n",
      "Wrote amazon_prefix_target_part0076.parquet  (#pairs=200,000)  total_pairs=10,700,712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  47%|████▋     | 26/55 [08:54<09:39, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0077.parquet  (#pairs=12,458)  total_pairs=10,713,170\n",
      "Wrote amazon_prefix_target_part0078.parquet  (#pairs=200,000)  total_pairs=10,913,170\n",
      "Wrote amazon_prefix_target_part0079.parquet  (#pairs=200,000)  total_pairs=11,113,170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  49%|████▉     | 27/55 [09:14<09:18, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0080.parquet  (#pairs=10,526)  total_pairs=11,123,696\n",
      "Wrote amazon_prefix_target_part0081.parquet  (#pairs=200,000)  total_pairs=11,323,696\n",
      "Wrote amazon_prefix_target_part0082.parquet  (#pairs=200,000)  total_pairs=11,523,696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  51%|█████     | 28/55 [09:34<08:55, 19.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0083.parquet  (#pairs=13,445)  total_pairs=11,537,141\n",
      "Wrote amazon_prefix_target_part0084.parquet  (#pairs=200,000)  total_pairs=11,737,141\n",
      "Wrote amazon_prefix_target_part0085.parquet  (#pairs=200,000)  total_pairs=11,937,141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  53%|█████▎    | 29/55 [09:54<08:39, 19.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0086.parquet  (#pairs=11,204)  total_pairs=11,948,345\n",
      "Wrote amazon_prefix_target_part0087.parquet  (#pairs=200,000)  total_pairs=12,148,345\n",
      "Wrote amazon_prefix_target_part0088.parquet  (#pairs=200,000)  total_pairs=12,348,345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  55%|█████▍    | 30/55 [10:15<08:25, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0089.parquet  (#pairs=12,325)  total_pairs=12,360,670\n",
      "Wrote amazon_prefix_target_part0090.parquet  (#pairs=200,000)  total_pairs=12,560,670\n",
      "Wrote amazon_prefix_target_part0091.parquet  (#pairs=200,000)  total_pairs=12,760,670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  56%|█████▋    | 31/55 [10:36<08:10, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0092.parquet  (#pairs=10,191)  total_pairs=12,770,861\n",
      "Wrote amazon_prefix_target_part0093.parquet  (#pairs=200,000)  total_pairs=12,970,861\n",
      "Wrote amazon_prefix_target_part0094.parquet  (#pairs=200,000)  total_pairs=13,170,861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  58%|█████▊    | 32/55 [10:57<07:58, 20.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0095.parquet  (#pairs=11,914)  total_pairs=13,182,775\n",
      "Wrote amazon_prefix_target_part0096.parquet  (#pairs=200,000)  total_pairs=13,382,775\n",
      "Wrote amazon_prefix_target_part0097.parquet  (#pairs=200,000)  total_pairs=13,582,775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  60%|██████    | 33/55 [11:18<07:39, 20.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0098.parquet  (#pairs=12,187)  total_pairs=13,594,962\n",
      "Wrote amazon_prefix_target_part0099.parquet  (#pairs=200,000)  total_pairs=13,794,962\n",
      "Wrote amazon_prefix_target_part0100.parquet  (#pairs=200,000)  total_pairs=13,994,962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  62%|██████▏   | 34/55 [11:40<07:20, 21.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0101.parquet  (#pairs=10,705)  total_pairs=14,005,667\n",
      "Wrote amazon_prefix_target_part0102.parquet  (#pairs=200,000)  total_pairs=14,205,667\n",
      "Wrote amazon_prefix_target_part0103.parquet  (#pairs=200,000)  total_pairs=14,405,667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  64%|██████▎   | 35/55 [12:03<07:14, 21.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0104.parquet  (#pairs=11,652)  total_pairs=14,417,319\n",
      "Wrote amazon_prefix_target_part0105.parquet  (#pairs=200,000)  total_pairs=14,617,319\n",
      "Wrote amazon_prefix_target_part0106.parquet  (#pairs=200,000)  total_pairs=14,817,319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  65%|██████▌   | 36/55 [12:24<06:45, 21.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0107.parquet  (#pairs=12,190)  total_pairs=14,829,509\n",
      "Wrote amazon_prefix_target_part0108.parquet  (#pairs=200,000)  total_pairs=15,029,509\n",
      "Wrote amazon_prefix_target_part0109.parquet  (#pairs=200,000)  total_pairs=15,229,509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  67%|██████▋   | 37/55 [12:44<06:18, 21.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0110.parquet  (#pairs=12,720)  total_pairs=15,242,229\n",
      "Wrote amazon_prefix_target_part0111.parquet  (#pairs=200,000)  total_pairs=15,442,229\n",
      "Wrote amazon_prefix_target_part0112.parquet  (#pairs=200,000)  total_pairs=15,642,229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  69%|██████▉   | 38/55 [13:04<05:53, 20.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0113.parquet  (#pairs=12,806)  total_pairs=15,655,035\n",
      "Wrote amazon_prefix_target_part0114.parquet  (#pairs=200,000)  total_pairs=15,855,035\n",
      "Wrote amazon_prefix_target_part0115.parquet  (#pairs=200,000)  total_pairs=16,055,035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  71%|███████   | 39/55 [13:24<05:30, 20.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0116.parquet  (#pairs=13,661)  total_pairs=16,068,696\n",
      "Wrote amazon_prefix_target_part0117.parquet  (#pairs=200,000)  total_pairs=16,268,696\n",
      "Wrote amazon_prefix_target_part0118.parquet  (#pairs=200,000)  total_pairs=16,468,696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  73%|███████▎  | 40/55 [13:45<05:10, 20.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0119.parquet  (#pairs=12,032)  total_pairs=16,480,728\n",
      "Wrote amazon_prefix_target_part0120.parquet  (#pairs=200,000)  total_pairs=16,680,728\n",
      "Wrote amazon_prefix_target_part0121.parquet  (#pairs=200,000)  total_pairs=16,880,728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  75%|███████▍  | 41/55 [14:07<04:53, 20.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0122.parquet  (#pairs=14,613)  total_pairs=16,895,341\n",
      "Wrote amazon_prefix_target_part0123.parquet  (#pairs=200,000)  total_pairs=17,095,341\n",
      "Wrote amazon_prefix_target_part0124.parquet  (#pairs=200,000)  total_pairs=17,295,341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  76%|███████▋  | 42/55 [14:27<04:28, 20.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0125.parquet  (#pairs=11,968)  total_pairs=17,307,309\n",
      "Wrote amazon_prefix_target_part0126.parquet  (#pairs=200,000)  total_pairs=17,507,309\n",
      "Wrote amazon_prefix_target_part0127.parquet  (#pairs=200,000)  total_pairs=17,707,309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  78%|███████▊  | 43/55 [14:48<04:11, 20.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0128.parquet  (#pairs=14,245)  total_pairs=17,721,554\n",
      "Wrote amazon_prefix_target_part0129.parquet  (#pairs=200,000)  total_pairs=17,921,554\n",
      "Wrote amazon_prefix_target_part0130.parquet  (#pairs=200,000)  total_pairs=18,121,554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  80%|████████  | 44/55 [15:10<03:52, 21.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0131.parquet  (#pairs=14,598)  total_pairs=18,136,152\n",
      "Wrote amazon_prefix_target_part0132.parquet  (#pairs=200,000)  total_pairs=18,336,152\n",
      "Wrote amazon_prefix_target_part0133.parquet  (#pairs=200,000)  total_pairs=18,536,152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  82%|████████▏ | 45/55 [15:30<03:28, 20.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0134.parquet  (#pairs=11,179)  total_pairs=18,547,331\n",
      "Wrote amazon_prefix_target_part0135.parquet  (#pairs=200,000)  total_pairs=18,747,331\n",
      "Wrote amazon_prefix_target_part0136.parquet  (#pairs=200,000)  total_pairs=18,947,331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  84%|████████▎ | 46/55 [15:50<03:05, 20.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0137.parquet  (#pairs=11,880)  total_pairs=18,959,211\n",
      "Wrote amazon_prefix_target_part0138.parquet  (#pairs=200,000)  total_pairs=19,159,211\n",
      "Wrote amazon_prefix_target_part0139.parquet  (#pairs=200,000)  total_pairs=19,359,211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  85%|████████▌ | 47/55 [16:11<02:44, 20.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0140.parquet  (#pairs=11,501)  total_pairs=19,370,712\n",
      "Wrote amazon_prefix_target_part0141.parquet  (#pairs=200,000)  total_pairs=19,570,712\n",
      "Wrote amazon_prefix_target_part0142.parquet  (#pairs=200,000)  total_pairs=19,770,712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  87%|████████▋ | 48/55 [16:31<02:23, 20.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0143.parquet  (#pairs=16,700)  total_pairs=19,787,412\n",
      "Wrote amazon_prefix_target_part0144.parquet  (#pairs=200,000)  total_pairs=19,987,412\n",
      "Wrote amazon_prefix_target_part0145.parquet  (#pairs=200,000)  total_pairs=20,187,412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  89%|████████▉ | 49/55 [16:52<02:04, 20.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0146.parquet  (#pairs=12,848)  total_pairs=20,200,260\n",
      "Wrote amazon_prefix_target_part0147.parquet  (#pairs=200,000)  total_pairs=20,400,260\n",
      "Wrote amazon_prefix_target_part0148.parquet  (#pairs=200,000)  total_pairs=20,600,260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  91%|█████████ | 50/55 [17:14<01:44, 20.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0149.parquet  (#pairs=12,466)  total_pairs=20,612,726\n",
      "Wrote amazon_prefix_target_part0150.parquet  (#pairs=200,000)  total_pairs=20,812,726\n",
      "Wrote amazon_prefix_target_part0151.parquet  (#pairs=200,000)  total_pairs=21,012,726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  93%|█████████▎| 51/55 [17:36<01:24, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0152.parquet  (#pairs=10,903)  total_pairs=21,023,629\n",
      "Wrote amazon_prefix_target_part0153.parquet  (#pairs=200,000)  total_pairs=21,223,629\n",
      "Wrote amazon_prefix_target_part0154.parquet  (#pairs=200,000)  total_pairs=21,423,629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  95%|█████████▍| 52/55 [18:00<01:06, 22.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0155.parquet  (#pairs=11,802)  total_pairs=21,435,431\n",
      "Wrote amazon_prefix_target_part0156.parquet  (#pairs=200,000)  total_pairs=21,635,431\n",
      "Wrote amazon_prefix_target_part0157.parquet  (#pairs=200,000)  total_pairs=21,835,431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  96%|█████████▋| 53/55 [18:22<00:44, 22.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0158.parquet  (#pairs=13,541)  total_pairs=21,848,972\n",
      "Wrote amazon_prefix_target_part0159.parquet  (#pairs=200,000)  total_pairs=22,048,972\n",
      "Wrote amazon_prefix_target_part0160.parquet  (#pairs=200,000)  total_pairs=22,248,972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts:  98%|█████████▊| 54/55 [18:44<00:22, 22.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0161.parquet  (#pairs=11,143)  total_pairs=22,260,115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating pairs from parts: 100%|██████████| 55/55 [18:46<00:00, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote amazon_prefix_target_part0162.parquet  (#pairs=30,053)  total_pairs=22,290,168\n",
      "\n",
      "Done generating prefix-target pairs.\n",
      "Total prefix-target parts written: 163\n",
      "Total pairs generated: 22290168\n",
      "Saved manifest: ..\\data\\processed\\amazon_parts_and_pairs_manifest.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell: session-summary (fixed) + streaming prefix->target generation to a dedicated folder\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "parts_dir = DATA_DIR / \"amazon_windows_parts\"   # folder with amazon_windows_sessions_part*.parquet\n",
    "pair_out_dir = DATA_DIR / \"amazon_prefix_parts\"\n",
    "pair_out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# --- 1) session-length aggregation across parts ---\n",
    "parts = sorted(parts_dir.glob(\"amazon_windows_sessions_part*.parquet\"))\n",
    "print(\"Found parts:\", len(parts))\n",
    "sess_counter = Counter()\n",
    "total_events = 0\n",
    "\n",
    "for p in tqdm.tqdm(parts, desc=\"Counting per-session lengths\"):\n",
    "    dfp = pd.read_parquet(p, columns=[\"session_id_real\"])\n",
    "    vc = dfp[\"session_id_real\"].value_counts()\n",
    "    total_events += len(dfp)\n",
    "    for sid, cnt in vc.items():\n",
    "        sess_counter[sid] += int(cnt)\n",
    "\n",
    "# convert Counter -> DataFrame\n",
    "sess_items = list(sess_counter.items())\n",
    "sess_df = pd.DataFrame(sess_items, columns=[\"session_id_real\", \"length\"])\n",
    "sess_df['length'] = sess_df['length'].astype(int)\n",
    "print(\"Total events counted across parts:\", total_events)\n",
    "print(\"Total sessions:\", len(sess_df))\n",
    "print(sess_df['length'].describe(percentiles=[.25,.5,.75,.9,.95,.99]))\n",
    "\n",
    "# Save session summary\n",
    "sess_summary_path = DATA_DIR / \"amazon_windows_session_summary_from_parts.csv\"\n",
    "sess_df.to_csv(sess_summary_path, index=False)\n",
    "print(\"Saved session summary CSV to:\", sess_summary_path)\n",
    "\n",
    "# --- 2) Generate prefix->target parts streaming from window parts ---\n",
    "FLUSH = 200_000   # number of pairs per output parquet file (tune if needed)\n",
    "pair_idx = 0\n",
    "total_pairs = 0\n",
    "\n",
    "def gen_pairs_from_df(df_part, session_col='session_id_real', item_col='item_id', max_prefix_len=50):\n",
    "    df_part = df_part.sort_values([session_col, 'timestamp'])\n",
    "    rows = []\n",
    "    for session_id, g in df_part.groupby(session_col):\n",
    "        items = g[item_col].astype(str).tolist()\n",
    "        if len(items) < 2:\n",
    "            continue\n",
    "        if len(items) > max_prefix_len + 1:\n",
    "            items = items[-(max_prefix_len + 1):]\n",
    "        for t in range(1, len(items)):\n",
    "            rows.append({\n",
    "                'dataset': g['dataset'].iloc[0],\n",
    "                'user_id': g['user_id'].iloc[0],\n",
    "                session_col: session_id,\n",
    "                'prefix_len': t,\n",
    "                'prefix': \" \".join(items[:t]),\n",
    "                'target': str(items[t])\n",
    "            })\n",
    "            if len(rows) >= FLUSH:\n",
    "                yield pd.DataFrame(rows)\n",
    "                rows = []\n",
    "    if rows:\n",
    "        yield pd.DataFrame(rows)\n",
    "\n",
    "print(\"\\nStart generating prefix->target parts (this can take time)...\")\n",
    "for p in tqdm.tqdm(parts, desc=\"Generating pairs from parts\"):\n",
    "    dfp = pd.read_parquet(p)\n",
    "    for df_pairs in gen_pairs_from_df(dfp, max_prefix_len=50):\n",
    "        outp = pair_out_dir / f\"amazon_prefix_target_part{pair_idx:04d}.parquet\"\n",
    "        df_pairs.to_parquet(outp, index=False)\n",
    "        total_pairs += len(df_pairs)\n",
    "        pair_idx += 1\n",
    "        print(f\"Wrote {outp.name}  (#pairs={len(df_pairs):,})  total_pairs={total_pairs:,}\")\n",
    "\n",
    "print(\"\\nDone generating prefix-target pairs.\")\n",
    "print(\"Total prefix-target parts written:\", len(list(pair_out_dir.glob(\"amazon_prefix_target_part*.parquet\"))))\n",
    "print(\"Total pairs generated:\", total_pairs)\n",
    "\n",
    "# Save small manifest of parts for downstream notebooks\n",
    "manifest = {\n",
    "    \"amazon_window_parts_dir\": str(parts_dir),\n",
    "    \"amazon_window_parts_count\": len(parts),\n",
    "    \"amazon_prefix_parts_dir\": str(pair_out_dir),\n",
    "    \"amazon_prefix_parts_count\": len(list(pair_out_dir.glob(\"amazon_prefix_target_part*.parquet\"))),\n",
    "    \"total_pairs\": total_pairs,\n",
    "    \"session_summary_csv\": str(sess_summary_path)\n",
    "}\n",
    "with open(DATA_DIR / \"amazon_parts_and_pairs_manifest.json\", \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "print(\"Saved manifest:\", DATA_DIR / \"amazon_parts_and_pairs_manifest.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a317cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window parts: 55\n",
      "Pair parts: 163\n",
      "Total window events (sum of parts): 27036156\n",
      "Total prefix-target pairs (sum of parts): 22290168\n",
      "\n",
      "Top 10 sessions by length (session_id_real, length):\n",
      "                      session_id_real  length\n",
      "AE4EQ5WN3XSND5SCGUA72VE4IUWQ__w12_120      20\n",
      "AE4EQ5WN3XSND5SCGUA72VE4IUWQ__w13_130      20\n",
      "AE4EQ5WN3XSND5SCGUA72VE4IUWQ__w14_140      20\n",
      "AE4EQ5WN3XSND5SCGUA72VE4IUWQ__w15_150      20\n",
      "AE4EQ5WN3XSND5SCGUA72VE4IUWQ__w16_160      20\n",
      "   AE223J6LBWPONMIKQGHAI3X5GNOQ__w0_0      20\n",
      "  AE223J6LBWPONMIKQGHAI3X5GNOQ__w1_10      20\n",
      "   AFSZ5DKMKILWGCDM3MW3ZLFYPREQ__w0_0      20\n",
      "   AFSZ5NHJ2Z4KHAQD5BXKIYZNJBBA__w0_0      20\n",
      "   AFVEWKIUT76O6SWOWUJ224NHDWHQ__w0_0      20\n",
      "\n",
      "Sample pair file: amazon_prefix_target_part0000.parquet  shape=(200000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id_real</th>\n",
       "      <th>prefix_len</th>\n",
       "      <th>prefix</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon_books_2023</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA__w0_0</td>\n",
       "      <td>1</td>\n",
       "      <td>0061058386</td>\n",
       "      <td>0441008534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon_books_2023</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA__w0_0</td>\n",
       "      <td>2</td>\n",
       "      <td>0061058386 0441008534</td>\n",
       "      <td>0441009239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon_books_2023</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA__w0_0</td>\n",
       "      <td>3</td>\n",
       "      <td>0061058386 0441008534 0441009239</td>\n",
       "      <td>0375826688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amazon_books_2023</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA__w0_0</td>\n",
       "      <td>4</td>\n",
       "      <td>0061058386 0441008534 0441009239 0375826688</td>\n",
       "      <td>B002KQ6BT6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amazon_books_2023</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA__w0_0</td>\n",
       "      <td>5</td>\n",
       "      <td>0061058386 0441008534 0441009239 0375826688 B0...</td>\n",
       "      <td>0765362643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amazon_books_2023</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA__w0_0</td>\n",
       "      <td>6</td>\n",
       "      <td>0061058386 0441008534 0441009239 0375826688 B0...</td>\n",
       "      <td>B002PEP4SC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>amazon_books_2023</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA__w0_0</td>\n",
       "      <td>7</td>\n",
       "      <td>0061058386 0441008534 0441009239 0375826688 B0...</td>\n",
       "      <td>B000R4LH3S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>amazon_books_2023</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA</td>\n",
       "      <td>AE22236AFRRSMQIKGG7TPTB75QEA__w0_0</td>\n",
       "      <td>8</td>\n",
       "      <td>0061058386 0441008534 0441009239 0375826688 B0...</td>\n",
       "      <td>B0060QST0Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dataset                       user_id  \\\n",
       "0  amazon_books_2023  AE22236AFRRSMQIKGG7TPTB75QEA   \n",
       "1  amazon_books_2023  AE22236AFRRSMQIKGG7TPTB75QEA   \n",
       "2  amazon_books_2023  AE22236AFRRSMQIKGG7TPTB75QEA   \n",
       "3  amazon_books_2023  AE22236AFRRSMQIKGG7TPTB75QEA   \n",
       "4  amazon_books_2023  AE22236AFRRSMQIKGG7TPTB75QEA   \n",
       "5  amazon_books_2023  AE22236AFRRSMQIKGG7TPTB75QEA   \n",
       "6  amazon_books_2023  AE22236AFRRSMQIKGG7TPTB75QEA   \n",
       "7  amazon_books_2023  AE22236AFRRSMQIKGG7TPTB75QEA   \n",
       "\n",
       "                      session_id_real  prefix_len  \\\n",
       "0  AE22236AFRRSMQIKGG7TPTB75QEA__w0_0           1   \n",
       "1  AE22236AFRRSMQIKGG7TPTB75QEA__w0_0           2   \n",
       "2  AE22236AFRRSMQIKGG7TPTB75QEA__w0_0           3   \n",
       "3  AE22236AFRRSMQIKGG7TPTB75QEA__w0_0           4   \n",
       "4  AE22236AFRRSMQIKGG7TPTB75QEA__w0_0           5   \n",
       "5  AE22236AFRRSMQIKGG7TPTB75QEA__w0_0           6   \n",
       "6  AE22236AFRRSMQIKGG7TPTB75QEA__w0_0           7   \n",
       "7  AE22236AFRRSMQIKGG7TPTB75QEA__w0_0           8   \n",
       "\n",
       "                                              prefix      target  \n",
       "0                                         0061058386  0441008534  \n",
       "1                              0061058386 0441008534  0441009239  \n",
       "2                   0061058386 0441008534 0441009239  0375826688  \n",
       "3        0061058386 0441008534 0441009239 0375826688  B002KQ6BT6  \n",
       "4  0061058386 0441008534 0441009239 0375826688 B0...  0765362643  \n",
       "5  0061058386 0441008534 0441009239 0375826688 B0...  B002PEP4SC  \n",
       "6  0061058386 0441008534 0441009239 0375826688 B0...  B000R4LH3S  \n",
       "7  0061058386 0441008534 0441009239 0375826688 B0...  B0060QST0Q  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell: quick sanity report (counts, top sessions, sample pair preview)\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "parts_dir = DATA_DIR / \"amazon_windows_parts\"\n",
    "pair_out_dir = DATA_DIR / \"amazon_prefix_parts\"\n",
    "\n",
    "# counts\n",
    "window_parts = sorted(parts_dir.glob(\"amazon_windows_sessions_part*.parquet\"))\n",
    "pair_parts = sorted(pair_out_dir.glob(\"amazon_prefix_target_part*.parquet\"))\n",
    "print(\"Window parts:\", len(window_parts))\n",
    "print(\"Pair parts:\", len(pair_parts))\n",
    "\n",
    "# total events across window parts (fast)\n",
    "total_window_events = sum(pd.read_parquet(p, columns=[\"session_id_real\"]).shape[0] for p in window_parts)\n",
    "print(\"Total window events (sum of parts):\", total_window_events)\n",
    "\n",
    "# total pairs across pair parts (fast)\n",
    "total_pairs = sum(pd.read_parquet(p, columns=[\"prefix\"]).shape[0] for p in pair_parts)\n",
    "print(\"Total prefix-target pairs (sum of parts):\", total_pairs)\n",
    "\n",
    "# top sessions by length: read session summary csv if exists\n",
    "sess_summary_csv = DATA_DIR / \"amazon_windows_session_summary_from_parts.csv\"\n",
    "if sess_summary_csv.exists():\n",
    "    sess_df = pd.read_csv(sess_summary_csv)\n",
    "    top_sessions = sess_df.sort_values(\"length\", ascending=False).head(10)\n",
    "    print(\"\\nTop 10 sessions by length (session_id_real, length):\")\n",
    "    print(top_sessions[[\"session_id_real\",\"length\"]].to_string(index=False))\n",
    "else:\n",
    "    print(\"Session summary CSV not found:\", sess_summary_csv)\n",
    "\n",
    "# sample one pair-part and show head\n",
    "if pair_parts:\n",
    "    sample_pair = pair_parts[0]\n",
    "    df_sample = pd.read_parquet(sample_pair)\n",
    "    print(f\"\\nSample pair file: {sample_pair.name}  shape={df_sample.shape}\")\n",
    "    display(df_sample.head(8))\n",
    "else:\n",
    "    print(\"No pair parts found in\", pair_out_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276da00",
   "metadata": {},
   "source": [
    "#### E — Process MARS using 1-hour gap, then generate prefix-targets\n",
    "This uses the sessionization-by-gap function and then generate prefix-target pairs (streamed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e482ed4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MARS interactions: 3659\n",
      "dataset                     object\n",
      "user_id                     object\n",
      "session_id                  object\n",
      "item_id                     object\n",
      "timestamp           datetime64[ns]\n",
      "interaction_type            object\n",
      "dtype: object\n",
      "No rating/watch_percentage field found; keeping all interactions: 3659\n",
      "Total sessions before filtering: 1275\n",
      "Total sessions after filtering (len >= 2): 549\n",
      "count    549.000000\n",
      "mean       5.335155\n",
      "std        6.348793\n",
      "min        2.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        5.000000\n",
      "max       50.000000\n",
      "Name: session_length, dtype: float64\n",
      "Saved MARS sessions to: ..\\data\\processed\\mars_sessions.parquet\n",
      "Saved MARS session summary to: ..\\data\\processed\\mars_session_summary.csv\n",
      "Saved MARS prefix-target pairs to: ..\\data\\processed\\mars_prefix_target.parquet\n",
      "MARS pairs: 2380\n",
      "\n",
      "--- Diagnostics ---\n",
      "Interactions after filtering: 2929\n",
      "Sessions (len>=2): 549\n",
      "Pairs generated: 2380\n",
      "count    549.000000\n",
      "mean       5.335155\n",
      "std        6.348793\n",
      "min        2.000000\n",
      "25%        2.000000\n",
      "50%        3.000000\n",
      "75%        5.000000\n",
      "max       50.000000\n",
      "Name: session_length, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id_real</th>\n",
       "      <th>prefix_len</th>\n",
       "      <th>prefix</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>1</td>\n",
       "      <td>52609</td>\n",
       "      <td>52616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>2</td>\n",
       "      <td>52609 52616</td>\n",
       "      <td>52615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>3</td>\n",
       "      <td>52609 52616 52615</td>\n",
       "      <td>52610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>4</td>\n",
       "      <td>52609 52616 52615 52610</td>\n",
       "      <td>52614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>5</td>\n",
       "      <td>52609 52616 52615 52610 52614</td>\n",
       "      <td>52618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>6</td>\n",
       "      <td>52609 52616 52615 52610 52614 52618</td>\n",
       "      <td>52611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>7</td>\n",
       "      <td>52609 52616 52615 52610 52614 52618 52611</td>\n",
       "      <td>52612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>8</td>\n",
       "      <td>52609 52616 52615 52610 52614 52618 52611 52612</td>\n",
       "      <td>52617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset user_id session_id_real  prefix_len  \\\n",
       "0    mars  104074      104074__s2           1   \n",
       "1    mars  104074      104074__s2           2   \n",
       "2    mars  104074      104074__s2           3   \n",
       "3    mars  104074      104074__s2           4   \n",
       "4    mars  104074      104074__s2           5   \n",
       "5    mars  104074      104074__s2           6   \n",
       "6    mars  104074      104074__s2           7   \n",
       "7    mars  104074      104074__s2           8   \n",
       "\n",
       "                                            prefix target  \n",
       "0                                            52609  52616  \n",
       "1                                      52609 52616  52615  \n",
       "2                                52609 52616 52615  52610  \n",
       "3                          52609 52616 52615 52610  52614  \n",
       "4                    52609 52616 52615 52610 52614  52618  \n",
       "5              52609 52616 52615 52610 52614 52618  52611  \n",
       "6        52609 52616 52615 52610 52614 52618 52611  52612  \n",
       "7  52609 52616 52615 52610 52614 52618 52611 52612  52617  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell: Process MARS with 1-hour gap and generate prefix->target pairs ---\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tqdm\n",
    "import json\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "mars_in = DATA_DIR / \"mars_interactions.parquet\"\n",
    "assert mars_in.exists(), f\"File not found: {mars_in}\"\n",
    "\n",
    "# Parameters\n",
    "MARS_GAP_SECONDS = 60 * 60    # 1 hour\n",
    "MIN_SESSION_LEN = 2\n",
    "MAX_PREFIX_LEN = 50           # cap for prefixes (safe)\n",
    "PAIR_FLUSH = 200_000          # flush pairs to disk in batches\n",
    "\n",
    "# Load\n",
    "df = pd.read_parquet(mars_in)\n",
    "print(\"Loaded MARS interactions:\", len(df))\n",
    "print(df.dtypes)\n",
    "# Ensure timestamp is datetime\n",
    "df['timestamp'] = pd.to_datetime(df.get('timestamp', df.get('created_at')))\n",
    "\n",
    "# Optional: convert explicit interactions to implicit-positive\n",
    "# two common rules: rating >=3 OR watch_percentage >= 50. Apply whichever field exists.\n",
    "if 'rating' in df.columns:\n",
    "    # treat rating >= 3 as positive (change threshold if you prefer)\n",
    "    df = df[df['rating'] >= 3].copy()\n",
    "    print(\"Filtered by rating >= 3; remaining:\", len(df))\n",
    "elif 'watch_percentage' in df.columns:\n",
    "    df = df[df['watch_percentage'] >= 50].copy()\n",
    "    print(\"Filtered by watch_percentage >= 50; remaining:\", len(df))\n",
    "else:\n",
    "    print(\"No rating/watch_percentage field found; keeping all interactions:\", len(df))\n",
    "\n",
    "# Sort\n",
    "df = df.sort_values(['user_id', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "# Sessionization by gap\n",
    "df['prev_ts'] = df.groupby('user_id')['timestamp'].shift(1)\n",
    "df['gap_s'] = (df['timestamp'] - df['prev_ts']).dt.total_seconds()\n",
    "df['new_session'] = (df['gap_s'].isna()) | (df['gap_s'] > MARS_GAP_SECONDS)\n",
    "df['sess_idx'] = df.groupby('user_id')['new_session'].cumsum().astype(int)\n",
    "df['session_id_real'] = df['user_id'].astype(str) + \"__s\" + df['sess_idx'].astype(str)\n",
    "\n",
    "# Optional: deduplicate consecutive identical items within same session\n",
    "# This removes immediate repeats like [i,i,i] -> [i]\n",
    "df = df.sort_values(['session_id_real', 'timestamp'])\n",
    "df['prev_item'] = df.groupby('session_id_real')['item_id'].shift(1)\n",
    "df = df[df['item_id'] != df['prev_item']].copy()\n",
    "df = df.drop(columns=['prev_item'])\n",
    "\n",
    "# Build session summary and filter by length >= MIN_SESSION_LEN\n",
    "session_summary = (\n",
    "    df.groupby('session_id_real')\n",
    "      .agg(dataset=('user_id','first'), user_id=('user_id','first'),\n",
    "           start_time=('timestamp','min'), end_time=('timestamp','max'),\n",
    "           session_length=('item_id','size'))\n",
    "      .reset_index()\n",
    ")\n",
    "valid_sessions = session_summary[session_summary['session_length'] >= MIN_SESSION_LEN]['session_id_real'].tolist()\n",
    "print(\"Total sessions before filtering:\", len(session_summary))\n",
    "session_summary = session_summary[session_summary['session_length'] >= MIN_SESSION_LEN].reset_index(drop=True)\n",
    "print(\"Total sessions after filtering (len >= 2):\", len(session_summary))\n",
    "print(session_summary['session_length'].describe())\n",
    "\n",
    "# Keep only valid sessions in df\n",
    "df = df[df['session_id_real'].isin(valid_sessions)].copy()\n",
    "# drop helper cols\n",
    "df = df.drop(columns=['prev_ts','gap_s','new_session','sess_idx'], errors='ignore')\n",
    "\n",
    "# Save sessionized interactions and summary\n",
    "mars_sessions_path = DATA_DIR / \"mars_sessions.parquet\"\n",
    "mars_summary_path = DATA_DIR / \"mars_session_summary.csv\"\n",
    "df.to_parquet(mars_sessions_path, index=False)\n",
    "session_summary.to_csv(mars_summary_path, index=False)\n",
    "print(\"Saved MARS sessions to:\", mars_sessions_path)\n",
    "print(\"Saved MARS session summary to:\", mars_summary_path)\n",
    "\n",
    "# Generate prefix->target pairs (streamed) and save in one parquet (small dataset ok in-memory)\n",
    "pairs = []\n",
    "for session_id, g in df.sort_values(['session_id_real','timestamp']).groupby('session_id_real'):\n",
    "    items = g['item_id'].astype(str).tolist()\n",
    "    # optional cap: keep last (MAX_PREFIX_LEN+1) items\n",
    "    if len(items) > MAX_PREFIX_LEN + 1:\n",
    "        items = items[-(MAX_PREFIX_LEN + 1):]\n",
    "    for t in range(1, len(items)):\n",
    "        prefix = items[:t]\n",
    "        target = items[t]\n",
    "        pairs.append({\n",
    "            'dataset': 'mars',\n",
    "            'user_id': g['user_id'].iloc[0],\n",
    "            'session_id_real': session_id,\n",
    "            'prefix_len': len(prefix),\n",
    "            'prefix': \" \".join(prefix),\n",
    "            'target': str(target)\n",
    "        })\n",
    "\n",
    "mars_pairs_df = pd.DataFrame(pairs)\n",
    "mars_pairs_path = DATA_DIR / \"mars_prefix_target.parquet\"\n",
    "mars_pairs_df.to_parquet(mars_pairs_path, index=False)\n",
    "print(\"Saved MARS prefix-target pairs to:\", mars_pairs_path)\n",
    "print(\"MARS pairs:\", len(mars_pairs_df))\n",
    "\n",
    "# Print quick diagnostics & sample\n",
    "print(\"\\n--- Diagnostics ---\")\n",
    "print(\"Interactions after filtering:\", len(df))\n",
    "print(\"Sessions (len>=2):\", len(session_summary))\n",
    "print(\"Pairs generated:\", len(mars_pairs_df))\n",
    "print(session_summary['session_length'].describe())\n",
    "\n",
    "display(mars_pairs_df.head(8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067f2c4e",
   "metadata": {},
   "source": [
    "#### F — Quick diagnostics to print & paste back for review\n",
    "\n",
    "Please paste the outputs (numbers & small table) here after you run:\n",
    "- # amazon parts written, total events written\n",
    "- approximate # amazon sessions (from summaries) and session length stats\n",
    "- total amazon prefix-target pairs generated\n",
    "- mars sessions count, mars session length describe\n",
    "- mars prefix-target pairs count and pairs.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "745995f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Amazon (window parts) ===\n",
      "parts found: 55\n",
      "total events across parts (sum): 27036156\n",
      "\n",
      "=== Amazon (pair parts) ===\n",
      "pair parts found: 163\n",
      "total prefix-target pairs (sum): 22290168\n",
      "\n",
      "=== MARS ===\n",
      "mars_sessions rows: 2929\n",
      "mars prefix-target pairs: 2380\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id_real</th>\n",
       "      <th>prefix_len</th>\n",
       "      <th>prefix</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>1</td>\n",
       "      <td>52609</td>\n",
       "      <td>52616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>2</td>\n",
       "      <td>52609 52616</td>\n",
       "      <td>52615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>3</td>\n",
       "      <td>52609 52616 52615</td>\n",
       "      <td>52610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>4</td>\n",
       "      <td>52609 52616 52615 52610</td>\n",
       "      <td>52614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>5</td>\n",
       "      <td>52609 52616 52615 52610 52614</td>\n",
       "      <td>52618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>6</td>\n",
       "      <td>52609 52616 52615 52610 52614 52618</td>\n",
       "      <td>52611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>7</td>\n",
       "      <td>52609 52616 52615 52610 52614 52618 52611</td>\n",
       "      <td>52612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mars</td>\n",
       "      <td>104074</td>\n",
       "      <td>104074__s2</td>\n",
       "      <td>8</td>\n",
       "      <td>52609 52616 52615 52610 52614 52618 52611 52612</td>\n",
       "      <td>52617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset user_id session_id_real  prefix_len  \\\n",
       "0    mars  104074      104074__s2           1   \n",
       "1    mars  104074      104074__s2           2   \n",
       "2    mars  104074      104074__s2           3   \n",
       "3    mars  104074      104074__s2           4   \n",
       "4    mars  104074      104074__s2           5   \n",
       "5    mars  104074      104074__s2           6   \n",
       "6    mars  104074      104074__s2           7   \n",
       "7    mars  104074      104074__s2           8   \n",
       "\n",
       "                                            prefix target  \n",
       "0                                            52609  52616  \n",
       "1                                      52609 52616  52615  \n",
       "2                                52609 52616 52615  52610  \n",
       "3                          52609 52616 52615 52610  52614  \n",
       "4                    52609 52616 52615 52610 52614  52618  \n",
       "5              52609 52616 52615 52610 52614 52618  52611  \n",
       "6        52609 52616 52615 52610 52614 52618 52611  52612  \n",
       "7  52609 52616 52615 52610 52614 52618 52611 52612  52617  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mars session summary path exists: ..\\data\\processed\\mars_session_summary.csv\n",
      "       session_id_real        dataset        user_id           start_time  \\\n",
      "count              549     549.000000     549.000000                  549   \n",
      "unique             549            NaN            NaN                  549   \n",
      "top         104074__s2            NaN            NaN  2019-07-22 15:27:08   \n",
      "freq                 1            NaN            NaN                    1   \n",
      "mean               NaN  400565.938069  400565.938069                  NaN   \n",
      "std                NaN  147004.255186  147004.255186                  NaN   \n",
      "min                NaN     672.000000     672.000000                  NaN   \n",
      "25%                NaN  279346.000000  279346.000000                  NaN   \n",
      "50%                NaN  404466.000000  404466.000000                  NaN   \n",
      "75%                NaN  537638.000000  537638.000000                  NaN   \n",
      "max                NaN  610262.000000  610262.000000                  NaN   \n",
      "\n",
      "                   end_time  session_length  \n",
      "count                   549      549.000000  \n",
      "unique                  549             NaN  \n",
      "top     2019-07-22 17:04:53             NaN  \n",
      "freq                      1             NaN  \n",
      "mean                    NaN        5.335155  \n",
      "std                     NaN        6.348793  \n",
      "min                     NaN        2.000000  \n",
      "25%                     NaN        2.000000  \n",
      "50%                     NaN        3.000000  \n",
      "75%                     NaN        5.000000  \n",
      "max                     NaN       50.000000  \n",
      "\n",
      "=== YOOCHOOSE (basic check) ===\n",
      "yoochoose events: 31744233\n",
      "unique sessions: 7990018\n",
      "unique items: 52069\n",
      "\n",
      "Quick summary (dict):\n",
      "{\n",
      "  \"amazon_window_parts\": 55,\n",
      "  \"amazon_window_events_sum\": 27036156,\n",
      "  \"amazon_pair_parts\": 163,\n",
      "  \"amazon_prefix_target_pairs_sum\": 22290168,\n",
      "  \"mars_sessions_rows\": 2929,\n",
      "  \"mars_pairs\": 2380,\n",
      "  \"yoo_events\": 31744233\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# F: Quick diagnostics for all processed datasets\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "\n",
    "# Amazon windows & pair parts directories\n",
    "amazon_windows_dir = DATA_DIR / \"amazon_windows_parts\"\n",
    "amazon_pairs_dir = DATA_DIR / \"amazon_prefix_parts\"\n",
    "\n",
    "# MARS paths\n",
    "mars_sessions_path = DATA_DIR / \"mars_sessions.parquet\"\n",
    "mars_pairs_path = DATA_DIR / \"mars_prefix_target.parquet\"\n",
    "mars_summary_path = DATA_DIR / \"mars_session_summary.csv\"\n",
    "\n",
    "# YOOCHOOSE path (already processed earlier)\n",
    "yoo_path = DATA_DIR / \"yoochoose_interactions.parquet\"\n",
    "\n",
    "# Gather file lists\n",
    "amazon_window_parts = sorted(amazon_windows_dir.glob(\"amazon_windows_sessions_part*.parquet\")) if amazon_windows_dir.exists() else []\n",
    "amazon_pair_parts = sorted(amazon_pairs_dir.glob(\"amazon_prefix_target_part*.parquet\")) if amazon_pairs_dir.exists() else []\n",
    "\n",
    "print(\"=== Amazon (window parts) ===\")\n",
    "print(\"parts found:\", len(amazon_window_parts))\n",
    "total_window_events = sum(pd.read_parquet(p, columns=[\"session_id_real\"]).shape[0] for p in amazon_window_parts) if amazon_window_parts else 0\n",
    "print(\"total events across parts (sum):\", total_window_events)\n",
    "\n",
    "print(\"\\n=== Amazon (pair parts) ===\")\n",
    "print(\"pair parts found:\", len(amazon_pair_parts))\n",
    "total_pairs = sum(pd.read_parquet(p, columns=[\"prefix\"]).shape[0] for p in amazon_pair_parts) if amazon_pair_parts else 0\n",
    "print(\"total prefix-target pairs (sum):\", total_pairs)\n",
    "\n",
    "print(\"\\n=== MARS ===\")\n",
    "if mars_sessions_path.exists():\n",
    "    df_mars = pd.read_parquet(mars_sessions_path)\n",
    "    print(\"mars_sessions rows:\", len(df_mars))\n",
    "else:\n",
    "    print(\"mars_sessions.parquet not found:\", mars_sessions_path)\n",
    "if mars_pairs_path.exists():\n",
    "    df_mars_pairs = pd.read_parquet(mars_pairs_path)\n",
    "    print(\"mars prefix-target pairs:\", len(df_mars_pairs))\n",
    "    display(df_mars_pairs.head(8))\n",
    "else:\n",
    "    print(\"mars_prefix_target.parquet not found:\", mars_pairs_path)\n",
    "if mars_summary_path.exists():\n",
    "    print(\"mars session summary path exists:\", mars_summary_path)\n",
    "    print(pd.read_csv(mars_summary_path).describe(include='all'))\n",
    "else:\n",
    "    print(\"mars_session_summary.csv not found:\", mars_summary_path)\n",
    "\n",
    "print(\"\\n=== YOOCHOOSE (basic check) ===\")\n",
    "if yoo_path.exists():\n",
    "    df_yoo = pd.read_parquet(yoo_path, columns=[\"session_id\",\"timestamp\",\"item_id\"])\n",
    "    print(\"yoochoose events:\", len(df_yoo))\n",
    "    print(\"unique sessions:\", df_yoo[\"session_id\"].nunique())\n",
    "    print(\"unique items:\", df_yoo[\"item_id\"].nunique())\n",
    "else:\n",
    "    print(\"yoochoose_interactions.parquet not found:\", yoo_path)\n",
    "\n",
    "# Print quick summary dict (for convenience)\n",
    "summary = {\n",
    "    \"amazon_window_parts\": len(amazon_window_parts),\n",
    "    \"amazon_window_events_sum\": int(total_window_events),\n",
    "    \"amazon_pair_parts\": len(amazon_pair_parts),\n",
    "    \"amazon_prefix_target_pairs_sum\": int(total_pairs),\n",
    "    \"mars_sessions_rows\": int(len(df_mars)) if 'df_mars' in locals() else None,\n",
    "    \"mars_pairs\": int(len(df_mars_pairs)) if 'df_mars_pairs' in locals() else None,\n",
    "    \"yoo_events\": int(len(df_yoo)) if 'df_yoo' in locals() else None\n",
    "}\n",
    "\n",
    "print(\"\\nQuick summary (dict):\")\n",
    "print(json.dumps(summary, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319bc20",
   "metadata": {},
   "source": [
    "#### G — Save metadata (paths & counts) for downstream notebooks\n",
    "\n",
    "Write a small JSON manifest so later notebooks can find files easily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93ce66d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote manifest to: ..\\data\\processed\\sessionization_manifest.json\n",
      "Manifest summary:\n",
      "{\n",
      "  \"amazon_windows_parts\": 55,\n",
      "  \"amazon_windows_events_sum\": 27036156,\n",
      "  \"amazon_prefix_parts\": 163,\n",
      "  \"amazon_prefix_pairs_sum\": 22290168,\n",
      "  \"mars_prefix_target\": \"..\\\\data\\\\processed\\\\mars_prefix_target.parquet\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# G: Write a manifest file for downstream notebooks (paths + counts)\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "manifest_path = DATA_DIR / \"sessionization_manifest.json\"\n",
    "\n",
    "# Build manifest content programmatically (read file lists and small counts)\n",
    "amazon_windows_dir = DATA_DIR / \"amazon_windows_parts\"\n",
    "amazon_pairs_dir = DATA_DIR / \"amazon_prefix_parts\"\n",
    "\n",
    "def list_files_str(p, pattern):\n",
    "    return [str(f) for f in sorted(p.glob(pattern))] if p.exists() else []\n",
    "\n",
    "manifest = {\n",
    "    \"amazon_windows_parts_dir\": str(amazon_windows_dir) if amazon_windows_dir.exists() else None,\n",
    "    \"amazon_windows_parts\": list_files_str(amazon_windows_dir, \"amazon_windows_sessions_part*.parquet\"),\n",
    "    \"amazon_windows_events_sum\": None,\n",
    "    \"amazon_prefix_parts_dir\": str(amazon_pairs_dir) if amazon_pairs_dir.exists() else None,\n",
    "    \"amazon_prefix_parts\": list_files_str(amazon_pairs_dir, \"amazon_prefix_target_part*.parquet\"),\n",
    "    \"amazon_prefix_pairs_sum\": None,\n",
    "    \"mars_sessions\": str(DATA_DIR / \"mars_sessions.parquet\") if (DATA_DIR / \"mars_sessions.parquet\").exists() else None,\n",
    "    \"mars_session_summary\": str(DATA_DIR / \"mars_session_summary.csv\") if (DATA_DIR / \"mars_session_summary.csv\").exists() else None,\n",
    "    \"mars_prefix_target\": str(DATA_DIR / \"mars_prefix_target.parquet\") if (DATA_DIR / \"mars_prefix_target.parquet\").exists() else None,\n",
    "    \"yoochoose_interactions\": str(DATA_DIR / \"yoochoose_interactions.parquet\") if (DATA_DIR / \"yoochoose_interactions.parquet\").exists() else None\n",
    "}\n",
    "\n",
    "# fill in numeric sums if possible (cheap operations)\n",
    "if manifest[\"amazon_windows_parts\"]:\n",
    "    manifest[\"amazon_windows_events_sum\"] = sum(pd.read_parquet(p, columns=[\"session_id_real\"]).shape[0] for p in amazon_windows_dir.glob(\"amazon_windows_sessions_part*.parquet\"))\n",
    "if manifest[\"amazon_prefix_parts\"]:\n",
    "    manifest[\"amazon_prefix_pairs_sum\"] = sum(pd.read_parquet(p, columns=[\"prefix\"]).shape[0] for p in amazon_pairs_dir.glob(\"amazon_prefix_target_part*.parquet\"))\n",
    "\n",
    "# write manifest\n",
    "with open(manifest_path, \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(\"Wrote manifest to:\", manifest_path)\n",
    "print(\"Manifest summary:\")\n",
    "print(json.dumps({k: (len(v) if isinstance(v, list) else v) for k, v in manifest.items() if k.endswith('_parts') or k.endswith('_sum') or k.endswith('mars_prefix_target')}, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "session-transfer-mooc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
