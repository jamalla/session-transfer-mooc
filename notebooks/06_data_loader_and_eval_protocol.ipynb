{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a5934f4",
   "metadata": {},
   "source": [
    "This notebook will:\n",
    "\n",
    "Load the shards from data/processed/tensor_shards_v2/\n",
    "Build PyTorch datasets + dataloaders for each {domain, split}\n",
    "Provide consistent evaluation metrics: Recall@K, MRR@K\n",
    "Provide an evaluation loop skeleton (model-agnostic)\n",
    "\n",
    "Assumption (from 05B outputs): shards contain\n",
    "input_ids, attention_mask, pos_ids, labels, lengths and MARS has 1 shard per split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f418dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set KMP_DUPLICATE_LIB_OK=TRUE — restart kernel and re-run cells now.\n"
     ]
    }
   ],
   "source": [
    "# Quick (unsafe) workaround to avoid the libiomp5md.dll crash.\n",
    "# Use this only to continue working in the notebook quickly.\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "print(\"Set KMP_DUPLICATE_LIB_OK=TRUE — restart kernel and re-run cells now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13aac869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06-01] Starting 06_data_loader_and_eval_protocol.ipynb\n",
      "[06-01] torch: 2.5.1\n"
     ]
    }
   ],
   "source": [
    "# CELL [06-01] — Imports & run header\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "print(\"[06-01] Starting 06_data_loader_and_eval_protocol.ipynb\")\n",
    "print(\"[06-01] torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d32b4",
   "metadata": {},
   "source": [
    "Config & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deede317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06-02] SHARDS_DIR: D:\\00_DS-ML-Workspace\\session-transfer-mooc\\data\\processed\\tensor_shards_v2\n",
      "[06-02] META_PATH: D:\\00_DS-ML-Workspace\\session-transfer-mooc\\data\\processed\\tensor_shards_v2\\metadata.json\n",
      "[06-02] DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "# CELL [06-02] — Config & paths\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "SHARDS_DIR = DATA_DIR / \"tensor_shards_v2\"\n",
    "META_PATH = SHARDS_DIR / \"metadata.json\"\n",
    "\n",
    "assert SHARDS_DIR.exists(), f\"[06-02] Missing SHARDS_DIR: {SHARDS_DIR}\"\n",
    "assert META_PATH.exists(), f\"[06-02] Missing metadata.json: {META_PATH}\"\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"[06-02] SHARDS_DIR:\", SHARDS_DIR.resolve())\n",
    "print(\"[06-02] META_PATH:\", META_PATH.resolve())\n",
    "print(\"[06-02] DEVICE:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c508302",
   "metadata": {},
   "source": [
    "Load metadata + sanity print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70604329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06-03] max_prefix_len: 20\n",
      "[06-03] pad_id: 0 unk_id: 1\n",
      "[06-03] shard_size: 250000\n",
      "[06-03] source_vocab_size: 200002\n",
      "[06-03] target_vocab_size: 702\n",
      "[06-03] tensor_fields: ['input_ids', 'attention_mask', 'pos_ids', 'labels', 'lengths']\n"
     ]
    }
   ],
   "source": [
    "# CELL [06-03] — Load metadata\n",
    "\n",
    "with open(META_PATH, \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "print(\"[06-03] max_prefix_len:\", meta[\"max_prefix_len\"])\n",
    "print(\"[06-03] pad_id:\", meta[\"pad_id\"], \"unk_id:\", meta[\"unk_id\"])\n",
    "print(\"[06-03] shard_size:\", meta[\"shard_size\"])\n",
    "print(\"[06-03] source_vocab_size:\", meta[\"vocab\"][\"source\"][\"size\"])\n",
    "print(\"[06-03] target_vocab_size:\", meta[\"vocab\"][\"target\"][\"size\"])\n",
    "print(\"[06-03] tensor_fields:\", meta[\"tensor_fields\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da54257",
   "metadata": {},
   "source": [
    "Discover shard files (from filesystem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b269928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06-04] amazon/train: 56 shards\n",
      "[06-04] amazon/val: 8 shards\n",
      "[06-04] amazon/test: 6 shards\n",
      "[06-04] yoochoose/train: 76 shards\n",
      "[06-04] yoochoose/val: 8 shards\n",
      "[06-04] yoochoose/test: 12 shards\n",
      "[06-04] mars/train: 1 shards\n",
      "[06-04] mars/val: 1 shards\n",
      "[06-04] mars/test: 1 shards\n"
     ]
    }
   ],
   "source": [
    "# CELL [06-04] — Discover shard files\n",
    "\n",
    "def list_shards(domain: str, split: str) -> List[Path]:\n",
    "    pattern = f\"{domain}_{split}_shard_*.pt\"\n",
    "    files = sorted(SHARDS_DIR.glob(pattern))\n",
    "    return files\n",
    "\n",
    "domains = [\"amazon\", \"yoochoose\", \"mars\"]\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "shard_index: Dict[str, Dict[str, List[Path]]] = {}\n",
    "for d in domains:\n",
    "    shard_index[d] = {}\n",
    "    for s in splits:\n",
    "        shard_index[d][s] = list_shards(d, s)\n",
    "        print(f\"[06-04] {d}/{s}: {len(shard_index[d][s])} shards\")\n",
    "\n",
    "# Hard assertions based on your real 05B output expectations\n",
    "assert len(shard_index[\"mars\"][\"train\"]) == 1, \"[06-04] Expected 1 mars train shard\"\n",
    "assert len(shard_index[\"mars\"][\"val\"]) == 1, \"[06-04] Expected 1 mars val shard\"\n",
    "assert len(shard_index[\"mars\"][\"test\"]) == 1, \"[06-04] Expected 1 mars test shard\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9acda8",
   "metadata": {},
   "source": [
    "Check a shard schema (must match exactly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86b55b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06-05] Sample shard: mars_train_shard_000.pt\n",
      "[06-05] Keys: ['input_ids', 'attention_mask', 'pos_ids', 'labels', 'lengths']\n",
      "[06-05] Shapes:\n",
      "   input_ids (1744, 20) torch.int64\n",
      "   attention_mask (1744, 20) torch.int64\n",
      "   pos_ids (1744, 20) torch.int64\n",
      "   labels (1744,) torch.int64\n",
      "   lengths (1744,) torch.int64\n",
      "[06-05] Schema checks PASSED\n"
     ]
    }
   ],
   "source": [
    "# CELL [06-05] — Validate shard schema\n",
    "\n",
    "REQUIRED_KEYS = [\"input_ids\", \"attention_mask\", \"pos_ids\", \"labels\", \"lengths\"]\n",
    "\n",
    "sample_path = shard_index[\"mars\"][\"train\"][0]\n",
    "sample = torch.load(sample_path, map_location=\"cpu\", weights_only=True)\n",
    "\n",
    "print(\"[06-05] Sample shard:\", sample_path.name)\n",
    "print(\"[06-05] Keys:\", list(sample.keys()))\n",
    "\n",
    "for k in REQUIRED_KEYS:\n",
    "    assert k in sample, f\"[06-05] Missing key in shard: {k}\"\n",
    "\n",
    "print(\"[06-05] Shapes:\")\n",
    "for k in REQUIRED_KEYS:\n",
    "    v = sample[k]\n",
    "    print(\"  \", k, tuple(v.shape), v.dtype)\n",
    "\n",
    "# Basic consistency checks\n",
    "n = sample[\"input_ids\"].shape[0]\n",
    "assert sample[\"labels\"].shape[0] == n\n",
    "assert sample[\"attention_mask\"].shape[0] == n\n",
    "assert sample[\"pos_ids\"].shape[0] == n\n",
    "assert sample[\"lengths\"].shape[0] == n\n",
    "\n",
    "print(\"[06-05] Schema checks PASSED\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83677043",
   "metadata": {},
   "source": [
    "Iterable shard dataset (memory safe)\n",
    "This streams shards one by one and yields individual examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4905387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL [06-06] — IterableDataset over shards (example-level)\n",
    "\n",
    "class ShardExamplesDataset(IterableDataset):\n",
    "    def __init__(self, shard_paths: List[Path], shuffle_shards: bool = False):\n",
    "        super().__init__()\n",
    "        self.shard_paths = list(shard_paths)\n",
    "        self.shuffle_shards = shuffle_shards\n",
    "\n",
    "    def __iter__(self):\n",
    "        paths = self.shard_paths\n",
    "        if self.shuffle_shards:\n",
    "            # shard-level shuffle (safe + cheap)\n",
    "            g = torch.Generator()\n",
    "            g.manual_seed(42)\n",
    "            idx = torch.randperm(len(paths), generator=g).tolist()\n",
    "            paths = [paths[i] for i in idx]\n",
    "\n",
    "        for sp in paths:\n",
    "            shard = torch.load(sp, map_location=\"cpu\", weights_only=True)\n",
    "            n = shard[\"input_ids\"].shape[0]\n",
    "\n",
    "            for i in range(n):\n",
    "                yield {\n",
    "                    \"input_ids\": shard[\"input_ids\"][i],\n",
    "                    \"attention_mask\": shard[\"attention_mask\"][i],\n",
    "                    \"pos_ids\": shard[\"pos_ids\"][i],\n",
    "                    \"labels\": shard[\"labels\"][i],\n",
    "                    \"lengths\": shard[\"lengths\"][i],\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e825070",
   "metadata": {},
   "source": [
    "Collate function (batch tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cd372ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL [06-07] — Collate function\n",
    "\n",
    "def collate_batch(batch: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:\n",
    "    return {\n",
    "        \"input_ids\": torch.stack([x[\"input_ids\"] for x in batch], dim=0),\n",
    "        \"attention_mask\": torch.stack([x[\"attention_mask\"] for x in batch], dim=0),\n",
    "        \"pos_ids\": torch.stack([x[\"pos_ids\"] for x in batch], dim=0),\n",
    "        \"labels\": torch.stack([x[\"labels\"] for x in batch], dim=0),\n",
    "        \"lengths\": torch.stack([x[\"lengths\"] for x in batch], dim=0),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa63dcb",
   "metadata": {},
   "source": [
    "DataLoader factory (domain/split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e7fee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL [06-08] — DataLoader factory\n",
    "\n",
    "def make_loader(domain: str, split: str, batch_size: int, shuffle_shards: bool) -> DataLoader:\n",
    "    shard_paths = shard_index[domain][split]\n",
    "    assert len(shard_paths) > 0, f\"[06-08] No shards found for {domain}/{split}\"\n",
    "\n",
    "    ds = ShardExamplesDataset(shard_paths, shuffle_shards=shuffle_shards)\n",
    "\n",
    "    # Note: For IterableDataset, shuffle is not supported here (we shuffle shards instead).\n",
    "    loader = DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,      # keep 0 for Windows stability\n",
    "        pin_memory=False,   # CPU training for now\n",
    "        collate_fn=collate_batch,\n",
    "        drop_last=False\n",
    "    )\n",
    "    print(f\"[06-08] Built loader {domain}/{split} | shards={len(shard_paths)} | batch_size={batch_size}\")\n",
    "    return loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f35aa",
   "metadata": {},
   "source": [
    "Quick loader test (MARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd1cb9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06-08] Built loader mars/train | shards=1 | batch_size=64\n",
      "[06-09] Batch keys: dict_keys(['input_ids', 'attention_mask', 'pos_ids', 'labels', 'lengths'])\n",
      "   input_ids (64, 20) torch.int64\n",
      "   attention_mask (64, 20) torch.int64\n",
      "   pos_ids (64, 20) torch.int64\n",
      "   labels (64,) torch.int64\n",
      "   lengths (64,) torch.int64\n",
      "[06-09] Example labels: [226, 129, 119, 209, 165, 150, 151, 197, 210, 90]\n"
     ]
    }
   ],
   "source": [
    "# CELL [06-09] — Quick loader test (MARS)\n",
    "\n",
    "mars_train_loader = make_loader(\"mars\", \"train\", batch_size=64, shuffle_shards=False)\n",
    "\n",
    "batch = next(iter(mars_train_loader))\n",
    "print(\"[06-09] Batch keys:\", batch.keys())\n",
    "for k, v in batch.items():\n",
    "    print(\"  \", k, tuple(v.shape), v.dtype)\n",
    "\n",
    "print(\"[06-09] Example labels:\", batch[\"labels\"][:10].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980e390",
   "metadata": {},
   "source": [
    "Evaluation Protocol (Metrics)\n",
    "\n",
    "These metrics assume the model returns scores/logits over item IDs: shape [B, V]\n",
    "(where V = vocab size) and labels is shape [B]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0cc13",
   "metadata": {},
   "source": [
    "Metric helpers (Recall@K, MRR@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b12d33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL [06-10] — Metrics\n",
    "\n",
    "@torch.no_grad()\n",
    "def recall_at_k(scores: torch.Tensor, labels: torch.Tensor, k: int) -> float:\n",
    "    \"\"\"\n",
    "    scores: [B, V]\n",
    "    labels: [B]\n",
    "    \"\"\"\n",
    "    topk = torch.topk(scores, k=k, dim=1).indices  # [B, k]\n",
    "    hit = (topk == labels.unsqueeze(1)).any(dim=1).float()  # [B]\n",
    "    return float(hit.mean().item())\n",
    "\n",
    "@torch.no_grad()\n",
    "def mrr_at_k(scores: torch.Tensor, labels: torch.Tensor, k: int) -> float:\n",
    "    \"\"\"\n",
    "    Mean Reciprocal Rank at K.\n",
    "    \"\"\"\n",
    "    topk = torch.topk(scores, k=k, dim=1).indices  # [B, k]\n",
    "    labels_exp = labels.unsqueeze(1)               # [B, 1]\n",
    "    match = (topk == labels_exp)                   # [B, k]\n",
    "\n",
    "    # rank positions are 1..k\n",
    "    ranks = torch.arange(1, k + 1, device=scores.device).unsqueeze(0)  # [1, k]\n",
    "    rr = torch.where(match, 1.0 / ranks, torch.zeros_like(ranks, dtype=torch.float))\n",
    "    rr_max = rr.max(dim=1).values  # [B]\n",
    "    return float(rr_max.mean().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a136be2",
   "metadata": {},
   "source": [
    "Eval loop (model-agnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0859146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The models later must implement\n",
    "# scores = model(batch)  # scores shape [B, V]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0ecea33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL [06-11] — Evaluation loop\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_model(model, loader: DataLoader, k: int = 20, device: str = DEVICE) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    total_recall = 0.0\n",
    "    total_mrr = 0.0\n",
    "    n_batches = 0\n",
    "\n",
    "    for bi, batch in enumerate(loader, 1):\n",
    "        # move to device\n",
    "        for key in [\"input_ids\", \"attention_mask\", \"pos_ids\", \"labels\", \"lengths\"]:\n",
    "            batch[key] = batch[key].to(device)\n",
    "\n",
    "        scores = model(batch)  # must return [B, V]\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        r = recall_at_k(scores, labels, k=k)\n",
    "        m = mrr_at_k(scores, labels, k=k)\n",
    "\n",
    "        total_recall += r\n",
    "        total_mrr += m\n",
    "        n_batches += 1\n",
    "\n",
    "        if bi % 50 == 0:\n",
    "            print(f\"[06-11][EVAL] batch={bi} recall@{k}={r:.4f} mrr@{k}={m:.4f}\")\n",
    "\n",
    "    return {\n",
    "        f\"Recall@{k}\": total_recall / max(n_batches, 1),\n",
    "        f\"MRR@{k}\": total_mrr / max(n_batches, 1),\n",
    "        \"batches\": n_batches\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36df6df",
   "metadata": {},
   "source": [
    "Dummy model sanity check (for pipeline only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe33db6",
   "metadata": {},
   "source": [
    "This is only to verify the evaluation loop works end-to-end.\n",
    "It returns random scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dc6c318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06-08] Built loader mars/val | shards=1 | batch_size=64\n",
      "[06-12] Dummy metrics: {'Recall@20': 0.028125, 'MRR@20': 0.004089781828224659, 'batches': 5}\n"
     ]
    }
   ],
   "source": [
    "# CELL [06-12] — Dummy model (pipeline sanity only)\n",
    "\n",
    "class DummyRandomModel(torch.nn.Module):\n",
    "    def __init__(self, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def forward(self, batch):\n",
    "        bsz = batch[\"input_ids\"].shape[0]\n",
    "        return torch.randn(bsz, self.vocab_size, device=batch[\"input_ids\"].device)\n",
    "\n",
    "dummy = DummyRandomModel(vocab_size=meta[\"vocab\"][\"target\"][\"size\"]).to(DEVICE)\n",
    "\n",
    "mars_val_loader = make_loader(\"mars\", \"val\", batch_size=64, shuffle_shards=False)\n",
    "\n",
    "metrics = evaluate_model(dummy, mars_val_loader, k=20, device=DEVICE)\n",
    "print(\"[06-12] Dummy metrics:\", metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "session-transfer-mooc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
