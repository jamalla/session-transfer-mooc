{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c26123",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "\n",
    "Adapters experiments on top of pretrained SASRec encoder.\n",
    "\n",
    "Goal:\n",
    "- Add lightweight adapters to each Transformer layer.\n",
    "- Copy encoder weights from pretrained checkpoint (if available).\n",
    "- Train adapters + out head (optionally item_emb) and evaluate on MARS.\n",
    "- Run a small grid over adapter bottleneck sizes and learning rates, saving best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b69b84",
   "metadata": {},
   "source": [
    "### Imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22acfcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set KMP_DUPLICATE_LIB_OK=TRUE — restart kernel and re-run cells now.\n"
     ]
    }
   ],
   "source": [
    "# Quick (unsafe) workaround to avoid the libiomp5md.dll crash.\n",
    "# Use this only to continue working in the notebook quickly.\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "print(\"Set KMP_DUPLICATE_LIB_OK=TRUE — restart kernel and re-run cells now.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14ddcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch, random, numpy as np, json, time\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "ROOT = Path('..')\n",
    "DATA_DIR = ROOT/'data'/'processed'\n",
    "CKPT_DIR = ROOT/'models'\n",
    "CKPT_DIR.mkdir(exist_ok=True)\n",
    "MARS_SHARD = DATA_DIR/'mars_shards'/'mars_shard_full.pt'\n",
    "VOCAB_FILE = DATA_DIR/'vocab_mars'/'item2id_mars.json'\n",
    "TEST_PAIRS = DATA_DIR/'mars_test_pairs.parquet'  # optional\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba41a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adapter(nn.Module):\n",
    "    def __init__(self, dim, bottleneck=16):\n",
    "        super().__init__()\n",
    "        self.down = nn.Linear(dim, bottleneck, bias=False)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.up = nn.Linear(bottleneck, dim, bias=False)\n",
    "    def forward(self, x):\n",
    "        # x: (B, L, D)\n",
    "        return x + self.up(self.act(self.down(x)))\n",
    "\n",
    "class SASRecSmall(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64, max_len=20, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.item_emb = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.pos_emb = nn.Embedding(max_len, embed_dim)\n",
    "        layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=4, dim_feedforward=2048, batch_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(layer, num_layers=num_layers)\n",
    "        self.out = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "    def forward(self, x):\n",
    "        B,L = x.size()\n",
    "        pos = torch.arange(L, device=x.device).unsqueeze(0).expand(B,L)\n",
    "        seq = self.item_emb(x) + self.pos_emb(pos)\n",
    "        seq = self.encoder(seq)\n",
    "        last = seq[:, -1, :]\n",
    "        logits = self.out(last)\n",
    "        return logits, last\n",
    "\n",
    "class SASRecWithAdapters(SASRecSmall):\n",
    "    def __init__(self, vocab_size, embed_dim=64, max_len=20, num_layers=2, adapter_bottleneck=16):\n",
    "        super().__init__(vocab_size, embed_dim, max_len, num_layers=num_layers)\n",
    "        # One adapter per encoder layer\n",
    "        self.adapters = nn.ModuleList([Adapter(embed_dim, adapter_bottleneck) for _ in range(num_layers)])\n",
    "    def forward(self, x):\n",
    "        B,L = x.size()\n",
    "        pos = torch.arange(L, device=x.device).unsqueeze(0).expand(B,L)\n",
    "        out = self.item_emb(x) + self.pos_emb(pos)\n",
    "        # iterate through encoder layers and adapters\n",
    "        for i, layer in enumerate(self.encoder.layers):\n",
    "            out = layer(out)\n",
    "            out = self.adapters[i](out)\n",
    "        last = out[:, -1, :]\n",
    "        logits = self.out(last)\n",
    "        return logits, last\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c657bfa",
   "metadata": {},
   "source": [
    "### Loss + evaluation helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f79e5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "def sampled_loss(final, y, emb_weights, num_neg=32):\n",
    "    # final: (B, D), y: (B,) indices, emb_weights: (V, D)\n",
    "    pos_scores = (final * emb_weights[y]).sum(dim=1)        # (B,)\n",
    "    V = emb_weights.size(0)\n",
    "    B = final.size(0)\n",
    "    neg_idx = torch.randint(0, V, (B, num_neg), device=final.device)\n",
    "    neg_w = emb_weights[neg_idx]                            # (B, N, D)\n",
    "    neg_scores = (neg_w * final.unsqueeze(1)).sum(dim=2)   # (B, N)\n",
    "    logits = torch.cat([pos_scores.unsqueeze(1), neg_scores], dim=1)  # (B, 1+N)\n",
    "    labels = torch.zeros(B, dtype=torch.long, device=final.device)\n",
    "    return F.cross_entropy(logits, labels)\n",
    "\n",
    "def eval_tensor_prefix(model, P_tensor, T_tensor, K=20):\n",
    "    model.eval()\n",
    "    hits = 0\n",
    "    rr = 0.0\n",
    "    tot = P_tensor.size(0)\n",
    "    with torch.no_grad():\n",
    "        for i in range(tot):\n",
    "            X = P_tensor[i].unsqueeze(0).to(DEVICE)\n",
    "            tgt = int(T_tensor[i].item())\n",
    "            _, final = model(X)\n",
    "            scores = final @ model.item_emb.weight.t()\n",
    "            topk = scores.topk(K, dim=1).indices.squeeze(0).cpu().numpy()\n",
    "            if tgt in topk:\n",
    "                hits += 1\n",
    "                rank = int((topk == tgt).nonzero()[0]) + 1\n",
    "                rr += 1.0 / rank\n",
    "    return hits / max(1, tot), rr / max(1, tot)\n",
    "\n",
    "def eval_test_df(model, df_test):\n",
    "    if df_test is None: return None, None\n",
    "    model.eval()\n",
    "    hits = 0\n",
    "    rr = 0.0\n",
    "    tot = len(df_test)\n",
    "    with torch.no_grad():\n",
    "        for _, r in df_test.iterrows():\n",
    "            pref = r['prefix'] if isinstance(r['prefix'], str) else ''\n",
    "            pref_ids = [int(x) for x in pref.split()] if pref else []\n",
    "            if len(pref_ids) > 20: pref_ids = pref_ids[-20:]\n",
    "            padded = [0] * (20 - len(pref_ids)) + pref_ids\n",
    "            X = torch.LongTensor([padded]).to(DEVICE)\n",
    "            tgt = int(r['target'])\n",
    "            _, final = model(X)\n",
    "            scores = final @ model.item_emb.weight.t()\n",
    "            topk = scores.topk(20, dim=1).indices.squeeze(0).cpu().numpy()\n",
    "            if tgt in topk:\n",
    "                hits += 1\n",
    "                rank = int((topk == tgt).nonzero()[0]) + 1\n",
    "                rr += 1.0 / rank\n",
    "    return hits / max(1, tot), rr / max(1, tot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4eb204",
   "metadata": {},
   "source": [
    "### Load MARS shard, splits, and optional test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67de17d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4824\\2978202254.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  mp = torch.load(MARS_SHARD)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test pairs: 238\n",
      "Pairs: 2380, train: 1904, val: 476, vocab: 777\n"
     ]
    }
   ],
   "source": [
    "mp = torch.load(MARS_SHARD)\n",
    "P_all = mp['prefix']; T_all = mp['target']\n",
    "N = P_all.size(0)\n",
    "VAL_FRAC = 0.2\n",
    "val_n = max(1, int(N * VAL_FRAC)); train_n = N - val_n\n",
    "train_P, train_T = P_all[:train_n], T_all[:train_n]\n",
    "val_P, val_T = P_all[train_n:], T_all[train_n:]\n",
    "\n",
    "df_test = None\n",
    "if TEST_PAIRS.exists():\n",
    "    import pandas as pd\n",
    "    df_test = pd.read_parquet(TEST_PAIRS)\n",
    "    print(\"Loaded test pairs:\", len(df_test))\n",
    "else:\n",
    "    print(\"No test pairs found at\", TEST_PAIRS)\n",
    "\n",
    "item2id = json.load(open(VOCAB_FILE))\n",
    "vocab = len(item2id)\n",
    "print(f\"Pairs: {N}, train: {train_n}, val: {val_n}, vocab: {vocab}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7d1a8f",
   "metadata": {},
   "source": [
    "### Grid config (bottlenecks, lrs, seeds) and small utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1129e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "BOTTLE_GRID = [8, 16, 32]       # adapter bottleneck sizes to try\n",
    "LR_GRID = [5e-4, 1e-4]          # learning rates to try\n",
    "SEEDS = [42, 100]               # seeds\n",
    "EPOCHS = 12\n",
    "BATCH = 32\n",
    "PATIENCE = 4\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class PairsDataset(Dataset):\n",
    "    def __init__(self, P, T): self.P=P; self.T=T\n",
    "    def __len__(self): return self.P.size(0)\n",
    "    def __getitem__(self, i): return self.P[i], int(self.T[i].item())\n",
    "train_ds = PairsDataset(train_P, train_T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aed116",
   "metadata": {},
   "source": [
    "### Main grid (train adapters + out); copies pretrained encoder if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2422580d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRETRAIN checkpoint: ..\\models\\sasrec_full_top200000_epoch0.pt_epoch0.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4824\\1530068434.py:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(PRETRAIN, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied pretrained weights into adapter model (b=8, lr=0.0005, seed=42)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4824\\2183514761.py:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  rank = int((topk == tgt).nonzero()[0]) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[adapters] b=8 lr=0.0005 seed=42 ep=0 loss=3.8681 val_rec=0.0273 val_mrr=0.0032\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0005 seed=42 ep=1 loss=3.7740 val_rec=0.0294 val_mrr=0.0041\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0005 seed=42 ep=2 loss=3.6945 val_rec=0.0336 val_mrr=0.0050\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0005 seed=42 ep=3 loss=3.6285 val_rec=0.0357 val_mrr=0.0043\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0005 seed=42 ep=4 loss=3.5793 val_rec=0.0294 val_mrr=0.0044\n",
      "[adapters] b=8 lr=0.0005 seed=42 ep=5 loss=3.5456 val_rec=0.0420 val_mrr=0.0049\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0005 seed=42 ep=6 loss=3.5238 val_rec=0.0357 val_mrr=0.0040\n",
      "[adapters] b=8 lr=0.0005 seed=42 ep=7 loss=3.4990 val_rec=0.0357 val_mrr=0.0040\n",
      "[adapters] b=8 lr=0.0005 seed=42 ep=8 loss=3.4742 val_rec=0.0357 val_mrr=0.0044\n",
      "[adapters] b=8 lr=0.0005 seed=42 ep=9 loss=3.4714 val_rec=0.0315 val_mrr=0.0045\n",
      "  early stopping\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b8_lr0.0005_s42.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_4824\\2183514761.py:51: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  rank = int((topk == tgt).nonzero()[0]) + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result row: {'bottleneck': 8, 'lr': 0.0005, 'seed': 42, 'val_rec': 0.04201680672268908, 'test_rec': 0.046218487394957986, 'test_mrr': 0.005527609948480464}\n",
      "Copied pretrained weights into adapter model (b=8, lr=0.0005, seed=100)\n",
      "[adapters] b=8 lr=0.0005 seed=100 ep=0 loss=3.7883 val_rec=0.0210 val_mrr=0.0030\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0005 seed=100 ep=1 loss=3.7046 val_rec=0.0357 val_mrr=0.0035\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0005 seed=100 ep=2 loss=3.6522 val_rec=0.0378 val_mrr=0.0035\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0005 seed=100 ep=3 loss=3.5990 val_rec=0.0399 val_mrr=0.0033\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0005 seed=100 ep=4 loss=3.5637 val_rec=0.0336 val_mrr=0.0029\n",
      "[adapters] b=8 lr=0.0005 seed=100 ep=5 loss=3.5246 val_rec=0.0294 val_mrr=0.0031\n",
      "[adapters] b=8 lr=0.0005 seed=100 ep=6 loss=3.4994 val_rec=0.0273 val_mrr=0.0043\n",
      "[adapters] b=8 lr=0.0005 seed=100 ep=7 loss=3.4796 val_rec=0.0399 val_mrr=0.0044\n",
      "  early stopping\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b8_lr0.0005_s100.pt\n",
      "Result row: {'bottleneck': 8, 'lr': 0.0005, 'seed': 100, 'val_rec': 0.03991596638655462, 'test_rec': 0.0546218487394958, 'test_mrr': 0.004422393781604958}\n",
      "Copied pretrained weights into adapter model (b=8, lr=0.0001, seed=42)\n",
      "[adapters] b=8 lr=0.0001 seed=42 ep=0 loss=3.9040 val_rec=0.0336 val_mrr=0.0043\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0001 seed=42 ep=1 loss=3.8931 val_rec=0.0315 val_mrr=0.0042\n",
      "[adapters] b=8 lr=0.0001 seed=42 ep=2 loss=3.8626 val_rec=0.0231 val_mrr=0.0033\n",
      "[adapters] b=8 lr=0.0001 seed=42 ep=3 loss=3.8426 val_rec=0.0231 val_mrr=0.0032\n",
      "[adapters] b=8 lr=0.0001 seed=42 ep=4 loss=3.8158 val_rec=0.0252 val_mrr=0.0032\n",
      "  early stopping\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b8_lr0.0001_s42.pt\n",
      "Result row: {'bottleneck': 8, 'lr': 0.0001, 'seed': 42, 'val_rec': 0.03361344537815126, 'test_rec': 0.025210084033613446, 'test_mrr': 0.003823634717044712}\n",
      "Copied pretrained weights into adapter model (b=8, lr=0.0001, seed=100)\n",
      "[adapters] b=8 lr=0.0001 seed=100 ep=0 loss=3.8518 val_rec=0.0231 val_mrr=0.0019\n",
      "  ✓ New best\n",
      "[adapters] b=8 lr=0.0001 seed=100 ep=1 loss=3.8073 val_rec=0.0210 val_mrr=0.0023\n",
      "[adapters] b=8 lr=0.0001 seed=100 ep=2 loss=3.7889 val_rec=0.0231 val_mrr=0.0025\n",
      "[adapters] b=8 lr=0.0001 seed=100 ep=3 loss=3.7554 val_rec=0.0189 val_mrr=0.0029\n",
      "[adapters] b=8 lr=0.0001 seed=100 ep=4 loss=3.7449 val_rec=0.0231 val_mrr=0.0031\n",
      "  early stopping\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b8_lr0.0001_s100.pt\n",
      "Result row: {'bottleneck': 8, 'lr': 0.0001, 'seed': 100, 'val_rec': 0.023109243697478993, 'test_rec': 0.01680672268907563, 'test_mrr': 0.0016039749233026544}\n",
      "Copied pretrained weights into adapter model (b=16, lr=0.0005, seed=42)\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=0 loss=3.8564 val_rec=0.0294 val_mrr=0.0039\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=1 loss=3.7068 val_rec=0.0210 val_mrr=0.0040\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=2 loss=3.6088 val_rec=0.0378 val_mrr=0.0041\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=3 loss=3.5362 val_rec=0.0504 val_mrr=0.0076\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=4 loss=3.4927 val_rec=0.0546 val_mrr=0.0091\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=5 loss=3.4499 val_rec=0.0651 val_mrr=0.0123\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=6 loss=3.4422 val_rec=0.0714 val_mrr=0.0121\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=7 loss=3.4261 val_rec=0.0819 val_mrr=0.0132\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=8 loss=3.3995 val_rec=0.0861 val_mrr=0.0165\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=9 loss=3.3854 val_rec=0.0840 val_mrr=0.0182\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=10 loss=3.3871 val_rec=0.0840 val_mrr=0.0193\n",
      "[adapters] b=16 lr=0.0005 seed=42 ep=11 loss=3.3698 val_rec=0.0819 val_mrr=0.0192\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b16_lr0.0005_s42.pt\n",
      "Result row: {'bottleneck': 16, 'lr': 0.0005, 'seed': 42, 'val_rec': 0.0861344537815126, 'test_rec': 0.08823529411764706, 'test_mrr': 0.017306032518588126}\n",
      "Copied pretrained weights into adapter model (b=16, lr=0.0005, seed=100)\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=0 loss=3.8175 val_rec=0.0147 val_mrr=0.0020\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=1 loss=3.6616 val_rec=0.0252 val_mrr=0.0034\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=2 loss=3.5936 val_rec=0.0231 val_mrr=0.0042\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=3 loss=3.5293 val_rec=0.0378 val_mrr=0.0051\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=4 loss=3.4908 val_rec=0.0483 val_mrr=0.0057\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=5 loss=3.4646 val_rec=0.0567 val_mrr=0.0076\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=6 loss=3.4471 val_rec=0.0609 val_mrr=0.0083\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=7 loss=3.4337 val_rec=0.0630 val_mrr=0.0093\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=8 loss=3.4114 val_rec=0.0651 val_mrr=0.0086\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=9 loss=3.4094 val_rec=0.0525 val_mrr=0.0091\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=10 loss=3.4043 val_rec=0.0609 val_mrr=0.0076\n",
      "[adapters] b=16 lr=0.0005 seed=100 ep=11 loss=3.3939 val_rec=0.0672 val_mrr=0.0105\n",
      "  ✓ New best\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b16_lr0.0005_s100.pt\n",
      "Result row: {'bottleneck': 16, 'lr': 0.0005, 'seed': 100, 'val_rec': 0.06722689075630252, 'test_rec': 0.07142857142857142, 'test_mrr': 0.012352143654664664}\n",
      "Copied pretrained weights into adapter model (b=16, lr=0.0001, seed=42)\n",
      "[adapters] b=16 lr=0.0001 seed=42 ep=0 loss=3.9509 val_rec=0.0273 val_mrr=0.0062\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=42 ep=1 loss=3.8899 val_rec=0.0294 val_mrr=0.0047\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=42 ep=2 loss=3.8380 val_rec=0.0315 val_mrr=0.0045\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=42 ep=3 loss=3.8054 val_rec=0.0336 val_mrr=0.0045\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=42 ep=4 loss=3.7747 val_rec=0.0315 val_mrr=0.0052\n",
      "[adapters] b=16 lr=0.0001 seed=42 ep=5 loss=3.7407 val_rec=0.0252 val_mrr=0.0037\n",
      "[adapters] b=16 lr=0.0001 seed=42 ep=6 loss=3.7247 val_rec=0.0252 val_mrr=0.0036\n",
      "[adapters] b=16 lr=0.0001 seed=42 ep=7 loss=3.6971 val_rec=0.0231 val_mrr=0.0031\n",
      "  early stopping\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b16_lr0.0001_s42.pt\n",
      "Result row: {'bottleneck': 16, 'lr': 0.0001, 'seed': 42, 'val_rec': 0.03361344537815126, 'test_rec': 0.04201680672268908, 'test_mrr': 0.004436333356872161}\n",
      "Copied pretrained weights into adapter model (b=16, lr=0.0001, seed=100)\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=0 loss=3.9461 val_rec=0.0063 val_mrr=0.0005\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=1 loss=3.8526 val_rec=0.0063 val_mrr=0.0005\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=2 loss=3.8095 val_rec=0.0126 val_mrr=0.0012\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=3 loss=3.7533 val_rec=0.0147 val_mrr=0.0019\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=4 loss=3.7238 val_rec=0.0168 val_mrr=0.0020\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=5 loss=3.6984 val_rec=0.0189 val_mrr=0.0023\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=6 loss=3.6698 val_rec=0.0210 val_mrr=0.0028\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=7 loss=3.6579 val_rec=0.0231 val_mrr=0.0033\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=8 loss=3.6292 val_rec=0.0273 val_mrr=0.0034\n",
      "  ✓ New best\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=9 loss=3.6117 val_rec=0.0252 val_mrr=0.0034\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=10 loss=3.6088 val_rec=0.0273 val_mrr=0.0034\n",
      "[adapters] b=16 lr=0.0001 seed=100 ep=11 loss=3.5884 val_rec=0.0252 val_mrr=0.0038\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b16_lr0.0001_s100.pt\n",
      "Result row: {'bottleneck': 16, 'lr': 0.0001, 'seed': 100, 'val_rec': 0.0273109243697479, 'test_rec': 0.029411764705882353, 'test_mrr': 0.003771286636429598}\n",
      "Copied pretrained weights into adapter model (b=32, lr=0.0005, seed=42)\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=0 loss=3.7408 val_rec=0.0189 val_mrr=0.0013\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=1 loss=3.5443 val_rec=0.0315 val_mrr=0.0048\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=2 loss=3.4756 val_rec=0.0609 val_mrr=0.0076\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=3 loss=3.4303 val_rec=0.0567 val_mrr=0.0110\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=4 loss=3.4233 val_rec=0.0651 val_mrr=0.0126\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=5 loss=3.3900 val_rec=0.0735 val_mrr=0.0125\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=6 loss=3.3715 val_rec=0.0882 val_mrr=0.0176\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=7 loss=3.3602 val_rec=0.0651 val_mrr=0.0153\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=8 loss=3.3270 val_rec=0.0672 val_mrr=0.0145\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=9 loss=3.3128 val_rec=0.0714 val_mrr=0.0200\n",
      "[adapters] b=32 lr=0.0005 seed=42 ep=10 loss=3.2966 val_rec=0.0798 val_mrr=0.0340\n",
      "  early stopping\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b32_lr0.0005_s42.pt\n",
      "Result row: {'bottleneck': 32, 'lr': 0.0005, 'seed': 42, 'val_rec': 0.08823529411764706, 'test_rec': 0.09663865546218488, 'test_mrr': 0.019927681411245426}\n",
      "Copied pretrained weights into adapter model (b=32, lr=0.0005, seed=100)\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=0 loss=3.7205 val_rec=0.0378 val_mrr=0.0036\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=1 loss=3.5708 val_rec=0.0336 val_mrr=0.0048\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=2 loss=3.4993 val_rec=0.0483 val_mrr=0.0089\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=3 loss=3.4511 val_rec=0.0546 val_mrr=0.0096\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=4 loss=3.4254 val_rec=0.0525 val_mrr=0.0087\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=5 loss=3.4140 val_rec=0.0588 val_mrr=0.0094\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=6 loss=3.3923 val_rec=0.0588 val_mrr=0.0101\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=7 loss=3.3818 val_rec=0.0630 val_mrr=0.0125\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=8 loss=3.3590 val_rec=0.0630 val_mrr=0.0137\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=9 loss=3.3455 val_rec=0.0798 val_mrr=0.0157\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=10 loss=3.3413 val_rec=0.0651 val_mrr=0.0149\n",
      "[adapters] b=32 lr=0.0005 seed=100 ep=11 loss=3.3091 val_rec=0.0630 val_mrr=0.0143\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b32_lr0.0005_s100.pt\n",
      "Result row: {'bottleneck': 32, 'lr': 0.0005, 'seed': 100, 'val_rec': 0.07983193277310924, 'test_rec': 0.07142857142857142, 'test_mrr': 0.016260971505592577}\n",
      "Copied pretrained weights into adapter model (b=32, lr=0.0001, seed=42)\n",
      "[adapters] b=32 lr=0.0001 seed=42 ep=0 loss=3.9286 val_rec=0.0357 val_mrr=0.0060\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0001 seed=42 ep=1 loss=3.7870 val_rec=0.0420 val_mrr=0.0060\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0001 seed=42 ep=2 loss=3.6976 val_rec=0.0315 val_mrr=0.0033\n",
      "[adapters] b=32 lr=0.0001 seed=42 ep=3 loss=3.6289 val_rec=0.0210 val_mrr=0.0016\n",
      "[adapters] b=32 lr=0.0001 seed=42 ep=4 loss=3.6047 val_rec=0.0168 val_mrr=0.0013\n",
      "[adapters] b=32 lr=0.0001 seed=42 ep=5 loss=3.5653 val_rec=0.0273 val_mrr=0.0020\n",
      "  early stopping\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b32_lr0.0001_s42.pt\n",
      "Result row: {'bottleneck': 32, 'lr': 0.0001, 'seed': 42, 'val_rec': 0.04201680672268908, 'test_rec': 0.02100840336134454, 'test_mrr': 0.003584986626229439}\n",
      "Copied pretrained weights into adapter model (b=32, lr=0.0001, seed=100)\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=0 loss=3.8707 val_rec=0.0252 val_mrr=0.0023\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=1 loss=3.7636 val_rec=0.0315 val_mrr=0.0027\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=2 loss=3.6933 val_rec=0.0294 val_mrr=0.0027\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=3 loss=3.6456 val_rec=0.0399 val_mrr=0.0038\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=4 loss=3.6095 val_rec=0.0357 val_mrr=0.0048\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=5 loss=3.5834 val_rec=0.0420 val_mrr=0.0057\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=6 loss=3.5589 val_rec=0.0357 val_mrr=0.0058\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=7 loss=3.5444 val_rec=0.0378 val_mrr=0.0062\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=8 loss=3.5264 val_rec=0.0399 val_mrr=0.0066\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=9 loss=3.5102 val_rec=0.0441 val_mrr=0.0076\n",
      "  ✓ New best\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=10 loss=3.5084 val_rec=0.0441 val_mrr=0.0078\n",
      "[adapters] b=32 lr=0.0001 seed=100 ep=11 loss=3.4889 val_rec=0.0462 val_mrr=0.0089\n",
      "  ✓ New best\n",
      "Saved adapter checkpoint: ..\\models\\adapters_b32_lr0.0001_s100.pt\n",
      "Result row: {'bottleneck': 32, 'lr': 0.0001, 'seed': 100, 'val_rec': 0.046218487394957986, 'test_rec': 0.04201680672268908, 'test_mrr': 0.008956916099773242}\n",
      "Adapters grid finished. Results saved to ..\\models\\adapters_grid_results.csv\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "# find pretrained checkpoint (prefer full)\n",
    "pretrain_candidates = sorted(CKPT_DIR.glob(\"*full*.pt\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "PRETRAIN = pretrain_candidates[0] if pretrain_candidates else None\n",
    "print(\"PRETRAIN checkpoint:\", PRETRAIN)\n",
    "\n",
    "for bottleneck in BOTTLE_GRID:\n",
    "    for lr in LR_GRID:\n",
    "        for seed in SEEDS:\n",
    "            # reproducibility\n",
    "            torch.manual_seed(seed); np.random.seed(seed); random.seed(seed)\n",
    "            model = SASRecWithAdapters(vocab_size=vocab, adapter_bottleneck=bottleneck).to(DEVICE)\n",
    "\n",
    "            # try copying pretrained weights (encoder/pos_emb/out/item_emb if shapes match)\n",
    "            if PRETRAIN is not None:\n",
    "                try:\n",
    "                    ck = torch.load(PRETRAIN, map_location='cpu')\n",
    "                    state = ck.get('model_state', ck)\n",
    "                    ms = model.state_dict()\n",
    "                    for k, v in state.items():\n",
    "                        if k in ms and ms[k].shape == v.shape:\n",
    "                            ms[k] = v\n",
    "                    model.load_state_dict(ms)\n",
    "                    print(f\"Copied pretrained weights into adapter model (b={bottleneck}, lr={lr}, seed={seed})\")\n",
    "                except Exception as e:\n",
    "                    print(\"Warning: failed to copy pretrained checkpoint:\", e)\n",
    "\n",
    "            # freeze base params except adapters + out (optionally keep item_emb frozen)\n",
    "            for name, p in model.named_parameters():\n",
    "                if name.startswith('adapters') or name.startswith('out'):\n",
    "                    p.requires_grad = True\n",
    "                else:\n",
    "                    # freeze encoder and pos_emb and item_emb initially\n",
    "                    p.requires_grad = False\n",
    "\n",
    "            train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=0,\n",
    "                                      collate_fn=lambda b: (torch.stack([x[0] for x in b]).to(DEVICE),\n",
    "                                                            torch.tensor([x[1] for x in b], device=DEVICE)))\n",
    "            opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=1e-6)\n",
    "\n",
    "            best_val = -1; best_state = None; bad = 0\n",
    "            for ep in range(EPOCHS):\n",
    "                model.train(); running = 0.0; steps = 0\n",
    "                for X, y in train_loader:\n",
    "                    _, final = model(X)\n",
    "                    loss = sampled_loss(final, y, model.item_emb.weight, num_neg=32)\n",
    "                    opt.zero_grad(); loss.backward(); opt.step()\n",
    "                    running += float(loss.item()); steps += 1\n",
    "                val_rec, val_mrr = eval_tensor_prefix(model, val_P, val_T, K=20)\n",
    "                print(f\"[adapters] b={bottleneck} lr={lr} seed={seed} ep={ep} loss={running/max(1,steps):.4f} val_rec={val_rec:.4f} val_mrr={val_mrr:.4f}\")\n",
    "                if val_rec > best_val:\n",
    "                    best_val = val_rec\n",
    "                    best_state = deepcopy(model.state_dict())\n",
    "                    bad = 0\n",
    "                    print(\"  ✓ New best\")\n",
    "                else:\n",
    "                    bad += 1\n",
    "                    if bad >= PATIENCE:\n",
    "                        print(\"  early stopping\")\n",
    "                        break\n",
    "\n",
    "            # save best\n",
    "            if best_state is not None:\n",
    "                ck_name = CKPT_DIR / f\"adapters_b{bottleneck}_lr{lr}_s{seed}.pt\"\n",
    "                torch.save({'model_state': best_state}, ck_name)\n",
    "                print(\"Saved adapter checkpoint:\", ck_name)\n",
    "            results.append({'bottleneck': bottleneck, 'lr': lr, 'seed': seed, 'val_rec': best_val})\n",
    "            # small evaluation on test if exists\n",
    "            if df_test is not None and best_state is not None:\n",
    "                # load best_state into model\n",
    "                ms = model.state_dict(); \n",
    "                for k in best_state: \n",
    "                    if k in ms and ms[k].shape == best_state[k].shape:\n",
    "                        ms[k] = best_state[k]\n",
    "                model.load_state_dict(ms)\n",
    "                trec, tmrr = eval_test_df(model, df_test)\n",
    "            else:\n",
    "                trec, tmrr = None, None\n",
    "            results[-1].update({'test_rec': trec, 'test_mrr': tmrr})\n",
    "            print(\"Result row:\", results[-1])\n",
    "# save grid results\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df.to_csv(CKPT_DIR/'adapters_grid_results.csv', index=False)\n",
    "print(\"Adapters grid finished. Results saved to\", CKPT_DIR/'adapters_grid_results.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab83a34",
   "metadata": {},
   "source": [
    "### Quick analysis & recommendation (Markdown + code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb601e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(CKPT_DIR/'adapters_grid_results.csv')\n",
    "df_sorted = df.sort_values('val_rec', ascending=False)\n",
    "print(\"Top results:\\n\", df_sorted.head(10))\n",
    "df_sorted.to_csv(CKPT_DIR/'adapters_grid_results_sorted.csv', index=False)\n",
    "print(\"Saved sorted results to\", CKPT_DIR/'adapters_grid_results_sorted.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "session-transfer-mooc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
